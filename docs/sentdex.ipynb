{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [Tokenizing Words and Sentences with NLTK](https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15350826/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr.', 'Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\"\n",
    "\n",
    "print(sent_tokenize(EXAMPLE_TEXT,\"czech\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [Stop words with NLTK](https://pythonprogramming.net/stop-words-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15350868/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'were', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u'their', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the', u'having', u'once'])\n['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print \"stop_words\", stop_words\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [Stemming words with NLTK](https://pythonprogramming.net/stemming-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15350897/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\npython\npython\npython\npythonli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\nis\nimport\nto\nby\nveri\npythonli\nwhile\nyou\nare\npython\nwith\npython\n.\nall\npython\nhave\npython\npoorli\nat\nleast\nonc\n.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "new_text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\"\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [Part of Speech Tagging with NLTK](https://pythonprogramming.net/part-of-speech-tagging-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15350929/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0402097902098 0.0735785953177 0.0383693045564 5720 299 230 22\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.0171328671329 0.0401337792642 0.0158642316916 5720 299 98 12\n0.00122377622378 0.0066889632107 0.000922339051835 5720 299 7 2\n0.00384615384615 0.0066889632107 0.00368935620734 5720 299 22 2\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00314685314685 0.0133779264214 0.00258254934514 5720 299 18 4\n0.00244755244755 0.0066889632107 0.00221361372441 5720 299 14 2\n0.00192307692308 0.00334448160535 0.00184467810367 5720 299 11 1\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.0138111888112 0.0200668896321 0.0134661501568 5720 299 79 6\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00122377622378 0.0167224080268 0.000368935620734 5720 299 7 5\n0.00244755244755 0.0167224080268 0.0016602102933 5720 299 14 5\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00996503496503 0.0066889632107 0.0101457295702 5720 299 57 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000524475524476 0.00334448160535 0.000368935620734 5720 299 3 1\n0.00034965034965 0.0066889632107 0.0 5720 299 2 2\n0.0295454545455 0.0066889632107 0.0308061243313 5720 299 169 2\n0.0131118881119 0.0100334448161 0.0132816823464 5720 299 75 3\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.0162587412587 0.0802675585284 0.0127282789153 5720 299 93 24\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00244755244755 0.00334448160535 0.00239808153477 5720 299 14 1\n0.00157342657343 0.0066889632107 0.00129127467257 5720 299 9 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.00314685314685 0.00334448160535 0.00313595277624 5720 299 18 1\n0.000524475524476 0.0066889632107 0.000184467810367 5720 299 3 2\n0.0034965034965 0.00334448160535 0.00350488839697 5720 299 20 1\n0.00611888111888 0.00334448160535 0.00627190555248 5720 299 35 1\n0.00524475524476 0.0066889632107 0.00516509869028 5720 299 30 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.0155594405594 0.00334448160535 0.0162331673123 5720 299 89 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00297202797203 0.00334448160535 0.00295148496587 5720 299 17 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.00594405594406 0.0267558528428 0.00479616306954 5720 299 34 8\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00262237762238 0.0100334448161 0.00221361372441 5720 299 15 3\n0.00104895104895 0.0133779264214 0.000368935620734 5720 299 6 4\n0.00314685314685 0.0066889632107 0.00295148496587 5720 299 18 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.0449300699301 0.0434782608696 0.0450101457296 5720 299 257 13\nPRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\n \nJanuary 31, 2006\n\nTHE PRESIDENT: Thank you all.\n[(u'PRESIDENT', 'NNP'), (u'GEORGE', 'NNP'), (u'W.', 'NNP'), (u'BUSH', 'NNP'), (u\"'S\", 'POS'), (u'ADDRESS', 'NNP'), (u'BEFORE', 'IN'), (u'A', 'NNP'), (u'JOINT', 'NNP'), (u'SESSION', 'NNP'), (u'OF', 'IN'), (u'THE', 'NNP'), (u'CONGRESS', 'NNP'), (u'ON', 'NNP'), (u'THE', 'NNP'), (u'STATE', 'NNP'), (u'OF', 'IN'), (u'THE', 'NNP'), (u'UNION', 'NNP'), (u'January', 'NNP'), (u'31', 'CD'), (u',', ','), (u'2006', 'CD'), (u'THE', 'NNP'), (u'PRESIDENT', 'NNP'), (u':', ':'), (u'Thank', 'NNP'), (u'you', 'PRP'), (u'all', 'DT'), (u'.', '.')]\nMr. Speaker, Vice President Cheney, members of Congress, members of the Supreme Court and diplomatic corps, distinguished guests, and fellow citizens: Today our nation lost a beloved, graceful, courageous woman who called America to its founding ideals and carried on a noble dream.\n[(u'Mr.', 'NNP'), (u'Speaker', 'NNP'), (u',', ','), (u'Vice', 'NNP'), (u'President', 'NNP'), (u'Cheney', 'NNP'), (u',', ','), (u'members', 'NNS'), (u'of', 'IN'), (u'Congress', 'NNP'), (u',', ','), (u'members', 'NNS'), (u'of', 'IN'), (u'the', 'DT'), (u'Supreme', 'NNP'), (u'Court', 'NNP'), (u'and', 'CC'), (u'diplomatic', 'JJ'), (u'corps', 'NN'), (u',', ','), (u'distinguished', 'JJ'), (u'guests', 'NNS'), (u',', ','), (u'and', 'CC'), (u'fellow', 'JJ'), (u'citizens', 'NNS'), (u':', ':'), (u'Today', 'VB'), (u'our', 'PRP$'), (u'nation', 'NN'), (u'lost', 'VBD'), (u'a', 'DT'), (u'beloved', 'VBN'), (u',', ','), (u'graceful', 'JJ'), (u',', ','), (u'courageous', 'JJ'), (u'woman', 'NN'), (u'who', 'WP'), (u'called', 'VBD'), (u'America', 'NNP'), (u'to', 'TO'), (u'its', 'PRP$'), (u'founding', 'NN'), (u'ideals', 'NNS'), (u'and', 'CC'), (u'carried', 'VBD'), (u'on', 'IN'), (u'a', 'DT'), (u'noble', 'JJ'), (u'dream', 'NN'), (u'.', '.')]\nTonight we are comforted by the hope of a glad reunion with the husband who was taken so long ago, and we are grateful for the good life of Coretta Scott King.\n[(u'Tonight', 'NN'), (u'we', 'PRP'), (u'are', 'VBP'), (u'comforted', 'VBN'), (u'by', 'IN'), (u'the', 'DT'), (u'hope', 'NN'), (u'of', 'IN'), (u'a', 'DT'), (u'glad', 'JJ'), (u'reunion', 'NN'), (u'with', 'IN'), (u'the', 'DT'), (u'husband', 'NN'), (u'who', 'WP'), (u'was', 'VBD'), (u'taken', 'VBN'), (u'so', 'RB'), (u'long', 'RB'), (u'ago', 'RB'), (u',', ','), (u'and', 'CC'), (u'we', 'PRP'), (u'are', 'VBP'), (u'grateful', 'JJ'), (u'for', 'IN'), (u'the', 'DT'), (u'good', 'JJ'), (u'life', 'NN'), (u'of', 'IN'), (u'Coretta', 'NNP'), (u'Scott', 'NNP'), (u'King', 'NNP'), (u'.', '.')]\n(Applause.)\n[(u'(', '('), (u'Applause', 'NNP'), (u'.', '.'), (u')', ')')]\nPresident George W. Bush reacts to applause during his State of the Union Address at the Capitol, Tuesday, Jan.\n[(u'President', 'NNP'), (u'George', 'NNP'), (u'W.', 'NNP'), (u'Bush', 'NNP'), (u'reacts', 'VBZ'), (u'to', 'TO'), (u'applause', 'VB'), (u'during', 'IN'), (u'his', 'PRP$'), (u'State', 'NNP'), (u'of', 'IN'), (u'the', 'DT'), (u'Union', 'NNP'), (u'Address', 'NNP'), (u'at', 'IN'), (u'the', 'DT'), (u'Capitol', 'NNP'), (u',', ','), (u'Tuesday', 'NNP'), (u',', ','), (u'Jan', 'NNP'), (u'.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:5]:\n",
    "            print i\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. [Chunking with NLTK](https://pythonprogramming.net/chunking-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15353114/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0402097902098 0.0735785953177 0.0383693045564 5720 299 230 22\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.0171328671329 0.0401337792642 0.0158642316916 5720 299 98 12\n0.00122377622378 0.0066889632107 0.000922339051835 5720 299 7 2\n0.00384615384615 0.0066889632107 0.00368935620734 5720 299 22 2\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00314685314685 0.0133779264214 0.00258254934514 5720 299 18 4\n0.00244755244755 0.0066889632107 0.00221361372441 5720 299 14 2\n0.00192307692308 0.00334448160535 0.00184467810367 5720 299 11 1\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.0138111888112 0.0200668896321 0.0134661501568 5720 299 79 6\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00122377622378 0.0167224080268 0.000368935620734 5720 299 7 5\n0.00244755244755 0.0167224080268 0.0016602102933 5720 299 14 5\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00996503496503 0.0066889632107 0.0101457295702 5720 299 57 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000524475524476 0.00334448160535 0.000368935620734 5720 299 3 1\n0.00034965034965 0.0066889632107 0.0 5720 299 2 2\n0.0295454545455 0.0066889632107 0.0308061243313 5720 299 169 2\n0.0131118881119 0.0100334448161 0.0132816823464 5720 299 75 3\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.0162587412587 0.0802675585284 0.0127282789153 5720 299 93 24\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00244755244755 0.00334448160535 0.00239808153477 5720 299 14 1\n0.00157342657343 0.0066889632107 0.00129127467257 5720 299 9 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.00314685314685 0.00334448160535 0.00313595277624 5720 299 18 1\n0.000524475524476 0.0066889632107 0.000184467810367 5720 299 3 2\n0.0034965034965 0.00334448160535 0.00350488839697 5720 299 20 1\n0.00611888111888 0.00334448160535 0.00627190555248 5720 299 35 1\n0.00524475524476 0.0066889632107 0.00516509869028 5720 299 30 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.0155594405594 0.00334448160535 0.0162331673123 5720 299 89 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00297202797203 0.00334448160535 0.00295148496587 5720 299 17 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.00594405594406 0.0267558528428 0.00479616306954 5720 299 34 8\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00262237762238 0.0100334448161 0.00221361372441 5720 299 15 3\n0.00104895104895 0.0133779264214 0.000368935620734 5720 299 6 4\n0.00314685314685 0.0066889632107 0.00295148496587 5720 299 18 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.0449300699301 0.0434782608696 0.0450101457296 5720 299 257 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n  (Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n  'S/POS\n  (Chunk ADDRESS/NNP)\n  BEFORE/IN\n  (Chunk A/NNP JOINT/NNP SESSION/NNP)\n  OF/IN\n  (Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n  OF/IN\n  (Chunk THE/NNP UNION/NNP January/NNP)\n  31/CD\n  ,/,\n  2006/CD\n  (Chunk THE/NNP PRESIDENT/NNP)\n  :/:\n  (Chunk Thank/NNP)\n  you/PRP\n  all/DT\n  ./.)\n(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n(Chunk ADDRESS/NNP)\n(Chunk A/NNP JOINT/NNP SESSION/NNP)\n(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n(Chunk THE/NNP UNION/NNP January/NNP)\n(Chunk THE/NNP PRESIDENT/NNP)\n(Chunk Thank/NNP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n  (Chunk Mr./NNP Speaker/NNP)\n  ,/,\n  (Chunk Vice/NNP President/NNP Cheney/NNP)\n  ,/,\n  members/NNS\n  of/IN\n  (Chunk Congress/NNP)\n  ,/,\n  members/NNS\n  of/IN\n  the/DT\n  (Chunk Supreme/NNP Court/NNP)\n  and/CC\n  diplomatic/JJ\n  corps/NN\n  ,/,\n  distinguished/JJ\n  guests/NNS\n  ,/,\n  and/CC\n  fellow/JJ\n  citizens/NNS\n  :/:\n  Today/VB\n  our/PRP$\n  nation/NN\n  lost/VBD\n  a/DT\n  beloved/VBN\n  ,/,\n  graceful/JJ\n  ,/,\n  courageous/JJ\n  woman/NN\n  who/WP\n  (Chunk called/VBD America/NNP)\n  to/TO\n  its/PRP$\n  founding/NN\n  ideals/NNS\n  and/CC\n  carried/VBD\n  on/IN\n  a/DT\n  noble/JJ\n  dream/NN\n  ./.)\n(Chunk Mr./NNP Speaker/NNP)\n(Chunk Vice/NNP President/NNP Cheney/NNP)\n(Chunk Congress/NNP)\n(Chunk Supreme/NNP Court/NNP)\n(Chunk called/VBD America/NNP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n  Tonight/NN\n  we/PRP\n  are/VBP\n  comforted/VBN\n  by/IN\n  the/DT\n  hope/NN\n  of/IN\n  a/DT\n  glad/JJ\n  reunion/NN\n  with/IN\n  the/DT\n  husband/NN\n  who/WP\n  was/VBD\n  taken/VBN\n  so/RB\n  long/RB\n  ago/RB\n  ,/,\n  and/CC\n  we/PRP\n  are/VBP\n  grateful/JJ\n  for/IN\n  the/DT\n  good/JJ\n  life/NN\n  of/IN\n  (Chunk Coretta/NNP Scott/NNP King/NNP)\n  ./.)\n(Chunk Coretta/NNP Scott/NNP King/NNP)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:3]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            print(chunked)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [Chinking with NLTK](https://pythonprogramming.net/chinking-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15353145/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0402097902098 0.0735785953177 0.0383693045564 5720 299 230 22\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.0171328671329 0.0401337792642 0.0158642316916 5720 299 98 12\n0.00122377622378 0.0066889632107 0.000922339051835 5720 299 7 2\n0.00384615384615 0.0066889632107 0.00368935620734 5720 299 22 2\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00314685314685 0.0133779264214 0.00258254934514 5720 299 18 4\n0.00244755244755 0.0066889632107 0.00221361372441 5720 299 14 2\n0.00192307692308 0.00334448160535 0.00184467810367 5720 299 11 1\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.0138111888112 0.0200668896321 0.0134661501568 5720 299 79 6\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00122377622378 0.0167224080268 0.000368935620734 5720 299 7 5\n0.00244755244755 0.0167224080268 0.0016602102933 5720 299 14 5\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00996503496503 0.0066889632107 0.0101457295702 5720 299 57 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000524475524476 0.00334448160535 0.000368935620734 5720 299 3 1\n0.00034965034965 0.0066889632107 0.0 5720 299 2 2\n0.0295454545455 0.0066889632107 0.0308061243313 5720 299 169 2\n0.0131118881119 0.0100334448161 0.0132816823464 5720 299 75 3\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.0162587412587 0.0802675585284 0.0127282789153 5720 299 93 24\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00244755244755 0.00334448160535 0.00239808153477 5720 299 14 1\n0.00157342657343 0.0066889632107 0.00129127467257 5720 299 9 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.00314685314685 0.00334448160535 0.00313595277624 5720 299 18 1\n0.000524475524476 0.0066889632107 0.000184467810367 5720 299 3 2\n0.0034965034965 0.00334448160535 0.00350488839697 5720 299 20 1\n0.00611888111888 0.00334448160535 0.00627190555248 5720 299 35 1\n0.00524475524476 0.0066889632107 0.00516509869028 5720 299 30 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.0155594405594 0.00334448160535 0.0162331673123 5720 299 89 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00297202797203 0.00334448160535 0.00295148496587 5720 299 17 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.00594405594406 0.0267558528428 0.00479616306954 5720 299 34 8\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00262237762238 0.0100334448161 0.00221361372441 5720 299 15 3\n0.00104895104895 0.0133779264214 0.000368935620734 5720 299 6 4\n0.00314685314685 0.0066889632107 0.00295148496587 5720 299 18 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.0449300699301 0.0434782608696 0.0450101457296 5720 299 257 13\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:3]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "\n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [Named Entity Recognition with NLTK](https://pythonprogramming.net/named-entity-recognition-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15353198/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0402097902098 0.0735785953177 0.0383693045564 5720 299 230 22\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.0171328671329 0.0401337792642 0.0158642316916 5720 299 98 12\n0.00122377622378 0.0066889632107 0.000922339051835 5720 299 7 2\n0.00384615384615 0.0066889632107 0.00368935620734 5720 299 22 2\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00314685314685 0.0133779264214 0.00258254934514 5720 299 18 4\n0.00244755244755 0.0066889632107 0.00221361372441 5720 299 14 2\n0.00192307692308 0.00334448160535 0.00184467810367 5720 299 11 1\n0.00157342657343 0.00334448160535 0.00147574248294 5720 299 9 1\n0.0138111888112 0.0200668896321 0.0134661501568 5720 299 79 6\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00122377622378 0.0167224080268 0.000368935620734 5720 299 7 5\n0.00244755244755 0.0167224080268 0.0016602102933 5720 299 14 5\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.00996503496503 0.0066889632107 0.0101457295702 5720 299 57 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000874125874126 0.0066889632107 0.000553403431101 5720 299 5 2\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.000524475524476 0.00334448160535 0.000368935620734 5720 299 3 1\n0.00034965034965 0.0066889632107 0.0 5720 299 2 2\n0.0295454545455 0.0066889632107 0.0308061243313 5720 299 169 2\n0.0131118881119 0.0100334448161 0.0132816823464 5720 299 75 3\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00437062937063 0.00334448160535 0.00442722744881 5720 299 25 1\n0.0162587412587 0.0802675585284 0.0127282789153 5720 299 93 24\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.00244755244755 0.00334448160535 0.00239808153477 5720 299 14 1\n0.00157342657343 0.0066889632107 0.00129127467257 5720 299 9 2\n0.0013986013986 0.00334448160535 0.00129127467257 5720 299 8 1\n0.00314685314685 0.00334448160535 0.00313595277624 5720 299 18 1\n0.000524475524476 0.0066889632107 0.000184467810367 5720 299 3 2\n0.0034965034965 0.00334448160535 0.00350488839697 5720 299 20 1\n0.00611888111888 0.00334448160535 0.00627190555248 5720 299 35 1\n0.00524475524476 0.0066889632107 0.00516509869028 5720 299 30 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.0155594405594 0.00334448160535 0.0162331673123 5720 299 89 1\n0.00227272727273 0.00334448160535 0.00221361372441 5720 299 13 1\n0.00297202797203 0.00334448160535 0.00295148496587 5720 299 17 1\n0.000699300699301 0.00334448160535 0.000553403431101 5720 299 4 1\n0.00594405594406 0.0267558528428 0.00479616306954 5720 299 34 8\n0.00034965034965 0.00334448160535 0.000184467810367 5720 299 2 1\n0.00262237762238 0.0100334448161 0.00221361372441 5720 299 15 3\n0.00104895104895 0.0133779264214 0.000368935620734 5720 299 6 4\n0.00314685314685 0.0066889632107 0.00295148496587 5720 299 18 2\n0.00104895104895 0.00334448160535 0.000922339051835 5720 299 6 1\n0.000174825174825 0.00334448160535 0.0 5720 299 1 1\n0.0449300699301 0.0434782608696 0.0450101457296 5720 299 257 13\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:3]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged, binary=True)\n",
    "            namedEnt.draw()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. [Lemmatizing with NLTK](https://pythonprogramming.net/lemmatizing-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15353273/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\ncactus\ngoose\nrock\npython\ngood\nbest\ndog\nrun\nrun\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"dog\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. [The corpora with NLTK](https://pythonprogramming.net/nltk-corpus-corpora-tutorial/) | [video](https://www.bilibili.com/video/av15353335/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\nltk\\__init__.pyc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The King James Bible]\n\nThe Old Testament of the King James Bible\n\nThe First Book of Moses:  Called Genesis\n\n\n1:1 In the beginning God created the heaven and the earth.\n1:2 And the earth was without form, and void; and darkness was upon\nthe face of the deep.\nAnd the Spirit of God moved upon the face of the\nwaters.\n1:3 And God said, Let there be light: and there was light.\n1:4 And God saw the light, that it was good: and God divided the light\nfrom the darkness.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__file__)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# sample text\n",
    "sample = gutenberg.raw(\"bible-kjv.txt\")\n",
    "\n",
    "tok = sent_tokenize(sample)\n",
    "\n",
    "for x in range(5):\n",
    "    print(tok[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. [Wordnet with NLTK](https://pythonprogramming.net/wordnet-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15353391/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan.n.01\nplan\na series of steps to be carried out or goals to be accomplished\n[u'they drew up a six-step plan', u'they discussed plans for a new bond issue']\nset([u'beneficial', u'right', u'secure', u'just', u'unspoilt', u'respectable', u'good', u'goodness', u'dear', u'salutary', u'ripe', u'expert', u'skillful', u'in_force', u'proficient', u'unspoiled', u'dependable', u'soundly', u'honorable', u'full', u'undecomposed', u'safe', u'adept', u'upright', u'trade_good', u'sound', u'in_effect', u'practiced', u'effective', u'commodity', u'estimable', u'well', u'honest', u'near', u'skilful', u'thoroughly', u'serious'])\nset([u'bad', u'badness', u'ill', u'evil', u'evilness'])\n0.909090909091\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syns = wordnet.synsets(\"program\")\n",
    "print(syns[0].name())\n",
    "print(syns[0].lemmas()[0].name())\n",
    "print(syns[0].definition())\n",
    "print(syns[0].examples())\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909090909091\n0.695652173913\n0.32\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('boat.n.01')\n",
    "print(w1.wup_similarity(w2))\n",
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('car.n.01')\n",
    "print(w1.wup_similarity(w2))\n",
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('cat.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. [Text Classification with NLTK](https://pythonprogramming.net/text-classification-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15355245/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([u'here', u'is', u'a', u'film', u'that', u'is', u'so', u'unexpected', u',', u'so', u'scary', u',', u'and', u'so', u'original', u'that', u'it', u'caught', u'me', u'off', u'guard', u'and', u'threw', u'me', u'for', u'a', u'loop', u'.', u'okay', u',', u'it', u'isn', u\"'\", u't', u'quite', u'original', u',', u'considering', u'it', u'is', u'a', u'sequel', u'to', u'the', u'box', u'office', u'hit', u'species', u',', u'but', u'it', u'certainly', u'is', u'smart', u'.', u'most', u'films', u'of', u'this', u'genre', u'are', u'reminiscent', u'of', u'those', u'cheesy', u'b', u'-', u'horror', u'films', u'from', u'the', u'50s', u'and', u'60s', u',', u'and', u'some', u'even', u'become', u'them', u'.', u'however', u',', u'as', u'we', u'learned', u'with', u'the', u'1995', u'small', u'-', u'budget', u'horror', u'/', u'sci', u'-', u'fi', u'film', u',', u'sometimes', u'expectations', u'can', u'be', u'shattered', u'.', u'a', u'lot', u'of', u'criticism', u'has', u'gone', u'against', u'this', u'film', u'(', u'from', u'what', u'i', u'have', u'read', u'so', u'far', u',', u'anyway', u'--', u'yep', u',', u'all', u'two', u'reviews', u')', u',', u'and', u'it', u'makes', u'me', u'wonder', u'why', u'these', u'types', u'of', u'films', u'are', u'automatically', u'dismissed', u'as', u'gory', u',', u'laughable', u'pieces', u'of', u'trash', u'.', u'but', u',', u'the', u'thing', u'is', u',', u'it', u'isn', u\"'\", u't', u'.', u'it', u\"'\", u's', u'well', u'made', u',', u'well', u'acted', u',', u'and', u'quite', u'intelligent', u'.', u'i', u'can', u'see', u'most', u'of', u'the', u'critics', u'now', u'complaining', u'about', u'the', u'level', u'of', u'gore', u'or', u'the', u'level', u'of', u'sexuality', u'in', u'the', u'film', u'.', u'but', u'the', u'species', u'series', u'isn', u\"'\", u't', u'about', u'the', u'lack', u'of', u'these', u'elements', u'.', u'it', u\"'\", u's', u'about', u'how', u'much', u'it', u'can', u'get', u'into', u'one', u'film', u'.', u'and', u'yet', u',', u'behind', u'it', u'all', u',', u'it', u'has', u'this', u'basic', u'premise', u'that', u'allows', u'it', u'to', u'get', u'away', u'with', u'doing', u'so', u'.', u'species', u'ii', u'begins', u'in', u'the', u'present', u'day', u',', u'though', u'it', u'seems', u'to', u'be', u'an', u'alternate', u'universe', u'.', u'many', u'films', u'(', u'especially', u'sci', u'-', u'fi', u'ones', u')', u'create', u'similar', u'timelines', u'as', u'our', u'realistic', u'one', u',', u'but', u'change', u'it', u'to', u'fit', u'the', u'film', u\"'\", u's', u'needs', u'.', u'species', u'ii', u'begins', u'with', u'the', u'arrival', u'of', u'an', u'american', u'spacecraft', u',', u'the', u'excursion', u',', u'landing', u'on', u'the', u'surface', u'of', u'mars', u'.', u'aboard', u'is', u'patrick', u'ross', u'(', u'justin', u'lazard', u')', u',', u'a', u'very', u'bright', u'and', u'very', u'handsome', u'astronaut', u'.', u'patrick', u'is', u'the', u'son', u'of', u'senator', u'ross', u'(', u'james', u'cromwell', u')', u',', u'who', u'just', u'wants', u'patrick', u'to', u'succeed', u'.', u'well', u',', u'it', u'would', u'seem', u'that', u'he', u'has', u'succeeded', u'.', u'landing', u'on', u'the', u'surface', u'of', u'mars', u',', u'he', u'is', u'the', u'first', u'human', u'being', u'to', u'ever', u'do', u'so', u'.', u'of', u'course', u',', u'he', u'isn', u\"'\", u't', u'the', u'first', u'ever', u'.', u'about', u'a', u'billion', u'years', u'ago', u',', u'an', u'alien', u'species', u'supposedly', u'landed', u'on', u'mars', u'and', u'destroyed', u'the', u'perfect', u'living', u'conditions', u'that', u'were', u'able', u'to', u'sustain', u'life', u'.', u'now', u',', u'of', u'course', u',', u'the', u'red', u'planet', u'is', u'cold', u'and', u'rocky', u'.', u'no', u'life', u'lives', u'on', u'it', u'.', u'that', u'is', u',', u'no', u'visible', u'life', u'.', u'patrick', u',', u'upon', u'leaving', u'the', u'spacecraft', u'and', u'landing', u'on', u'the', u'red', u'soil', u',', u'collects', u'samples', u'from', u'the', u'ground', u'.', u'he', u'takes', u'them', u'aboard', u',', u'and', u'puts', u'them', u'in', u'storage', u'.', u'unfortunately', u',', u'one', u'of', u'the', u'samples', u'contains', u'a', u'form', u'of', u'life', u',', u'and', u'it', u'gets', u'loose', u'when', u'it', u'is', u'heated', u'aboard', u'the', u'ship', u'.', u'just', u'prior', u'to', u'heading', u'back', u'to', u'earth', u',', u'this', u'life', u'form', u'creeps', u'along', u'the', u'floor', u'and', u'inhabits', u'the', u'earthlings', u'.', u'they', u'pass', u'out', u'for', u'approximately', u'seven', u'minutes', u',', u'and', u'then', u'shrug', u'it', u'off', u'as', u'nothing', u',', u'because', u'they', u'can', u\"'\", u't', u'even', u'remember', u'.', u'they', u'blame', u'it', u'on', u'a', u'technical', u'malfunction', u'.', u'back', u'on', u'earth', u',', u'patrick', u'begins', u'to', u'have', u'strong', u'urges', u'to', u'mate', u'with', u'as', u'many', u'women', u'as', u'possible', u'.', u'as', u'we', u'know', u'from', u'the', u'original', u',', u'this', u'is', u'because', u'the', u'alien', u'wants', u'to', u'breed', u'and', u'take', u'over', u'the', u'planet', u'.', u'however', u',', u'the', u'children', u'that', u'are', u'bred', u'are', u'half', u'-', u'human', u',', u'as', u'their', u'father', u'is', u'.', u'patrick', u'is', u'really', u'looking', u'for', u'another', u'alien', u'to', u'breed', u'with', u',', u'and', u'he', u'finds', u'it', u'in', u'eve', u'(', u'natasha', u'henstridge', u')', u'.', u'eve', u'was', u'cloned', u'from', u'dna', u'taken', u'from', u'sil', u',', u'the', u'original', u'alien', u'.', u'however', u',', u'this', u'time', u'around', u',', u'most', u'of', u'her', u'\"', u'alien', u'\"', u'urges', u'have', u'been', u'either', u'decreased', u'dramatically', u',', u'or', u'lie', u'dormant', u'.', u'the', u'project', u'is', u'led', u'by', u'dr', u'.', u'laura', u'baker', u'(', u'marg', u'helgenberger', u',', u'reprising', u'her', u'role', u'from', u'species', u')', u',', u'and', u'her', u'motives', u'seem', u'respectable', u'.', u'since', u'she', u'was', u'involved', u'with', u'the', u'original', u'alien', u'attack', u',', u'she', u'wants', u'to', u'learn', u'how', u'to', u'stop', u'the', u'alien', u'should', u'it', u'come', u'again', u'.', u'and', u'it', u'has', u'.', u'story', u'-', u'wise', u',', u'species', u'ii', u'is', u'much', u'stronger', u'than', u'its', u'predecessor', u',', u'but', u'it', u'is', u'also', u'much', u'stronger', u'than', u',', u'say', u',', u'aliens', u'(', u'hey', u',', u'i', u'love', u'the', u'film', u',', u'but', u'you', u'can', u\"'\", u't', u'tell', u'me', u'it', u'was', u'strong', u'on', u'story', u')', u'.', u'what', u'surprised', u'me', u'the', u'most', u'with', u'this', u'film', u'was', u'the', u'incorporation', u'of', u'historical', u'facts', u'into', u'the', u'screenplay', u'.', u'in', u'my', u'search', u'for', u'extraterrestrial', u'intelligence', u'course', u'in', u'college', u',', u'we', u'learned', u'about', u'a', u'piece', u'of', u'rock', u'from', u'mars', u'which', u'landed', u'in', u'one', u'of', u'the', u'poles', u'.', u'this', u'piece', u'of', u'rock', u'contained', u'fossils', u'which', u'may', u'have', u'been', u'proof', u'of', u'life', u'on', u'mars', u'(', u'later', u',', u'it', u'was', u'proven', u'that', u'it', u'was', u'not', u'a', u'living', u'creature', u'that', u'created', u'it', u')', u'.', u'the', u'script', u'uses', u'this', u'effectively', u',', u'but', u'also', u'manages', u'to', u'provide', u'a', u'well', u'-', u'balanced', u'plot', u'.', u'beginning', u'with', u'the', u'first', u'man', u'on', u'mars', u'(', u'something', u'i', u'have', u'always', u'dreamed', u'of', u'seeing', u')', u',', u'i', u'was', u'hoping', u'that', u'the', u'film', u'would', u'turn', u'this', u'element', u'into', u'a', u'useful', u'starting', u'point', u'for', u'the', u'movie', u'.', u'and', u'it', u'does', u'it', u'quite', u'well', u'.', u'the', u'characters', u'are', u'all', u'smart', u',', u'and', u'they', u'know', u'what', u'to', u'do', u'and', u'what', u'not', u'to', u'do', u'.', u'the', u'only', u'character', u'that', u'seems', u'a', u'little', u'cliched', u'is', u'the', u'general', u'(', u'george', u'dzundza', u')', u',', u'and', u'yet', u',', u'he', u'remains', u'logical', u'in', u'everything', u'he', u'does', u'.', u'there', u'are', u'the', u'obvious', u'flaws', u'of', u'course', u',', u'mostly', u'lying', u'in', u'the', u'technical', u'aspects', u'.', u'the', u'special', u'effects', u'are', u'only', u'mediocre', u',', u'and', u'some', u'are', u'just', u'plain', u'bad', u'.', u'but', u'for', u'the', u'most', u'part', u',', u'they', u'remain', u'believable', u'(', u'i', u'even', u'noticed', u'a', u'homage', u'to', u'the', u'alien', u'series', u'when', u'the', u'mothers', u'gave', u'birth', u'to', u'alien', u'children', u')', u'.', u'also', u',', u'the', u'most', u'realistic', u'ones', u'are', u'usually', u'the', u'goriest', u',', u'ranging', u'from', u'people', u'being', u'torn', u'open', u',', u'or', u'someone', u\"'\", u's', u'head', u'being', u'blown', u'off', u'.', u'however', u',', u'some', u'plot', u'elements', u'also', u'may', u'elicit', u'laughs', u'from', u'the', u'audience', u',', u'including', u'a', u'menage', u'a', u'troi', u'that', u'is', u'all', u'but', u'necessary', u'.', u'many', u'people', u'dislike', u'the', u'species', u'series', u'because', u'all', u'it', u'is', u'is', u'an', u'excuse', u'for', u'sex', u',', u'nudity', u',', u'and', u'gory', u'violence', u'.', u'however', u',', u'i', u'tend', u'to', u'disagree', u'.', u'what', u'were', u'the', u'alien', u'films', u'about', u'?', u'and', u',', u'if', u'an', u'alien', u'species', u'ever', u'did', u'come', u'to', u'earth', u',', u'and', u'their', u'sole', u'purpose', u'was', u'to', u'destroy', u'us', u',', u'wouldn', u\"'\", u't', u'you', u'mate', u'as', u'quickly', u'as', u'possible', u'with', u'as', u'many', u'people', u'as', u'possible', u'?', u'my', u'only', u'gripe', u'with', u'this', u'is', u'during', u'the', u'scene', u'where', u'patrick', u'goes', u'searching', u'for', u'a', u'mate', u'in', u'a', u'grocery', u'store', u'.', u'i', u'didn', u\"'\", u't', u'realize', u'that', u'aliens', u'were', u'that', u'picky', u'on', u'choosing', u'women', u'to', u'mate', u'with', u'(', u'i', u'just', u'assume', u'it', u'is', u'his', u'part', u'-', u'human', u'side', u'looking', u'for', u'the', u'most', u'beautiful', u'one', u')', u'.', u'the', u'acting', u'is', u'quite', u'good', u'for', u'this', u'kind', u'of', u'film', u'.', u'it', u'is', u'a', u'vast', u'improvement', u'over', u'the', u'first', u'film', u',', u'at', u'least', u'.', u'the', u'acting', u'is', u'the', u'key', u'element', u'to', u'this', u'film', u':', u'if', u'it', u'was', u'bad', u',', u'it', u'would', u'have', u'lowered', u'itself', u'into', u'camp', u';', u'if', u'it', u'was', u'good', u',', u'it', u'would', u'have', u'asked', u'for', u'comparison', u'with', u'films', u'like', u'aliens', u'.', u'okay', u',', u'so', u'it', u'isn', u\"'\", u't', u'that', u'good', u'.', u'george', u'dzundza', u'is', u'probably', u'the', u'most', u'obvious', u'mistake', u'on', u'casting', u',', u'as', u'his', u'over', u'-', u'the', u'-', u'top', u'impersonation', u'of', u'a', u'general', u'makes', u'him', u'annoying', u'and', u'distracting', u'.', u'natasha', u'henstridge', u'is', u'limited', u'this', u'time', u'around', u',', u'as', u'she', u'is', u'usually', u'enclosed', u'in', u'a', u'cage', u'.', u'however', u',', u'she', u'does', u'manage', u'a', u'very', u'impressive', u'performance', u'with', u'this', u'aspect', u'hindering', u'any', u'of', u'her', u'talent', u'.', u'oh', u'yeah', u',', u'and', u'she', u\"'\", u's', u'quite', u'fun', u'to', u'just', u'plain', u'watch', u'.', u'marg', u'helgenberger', u'is', u'immensely', u'better', u'this', u'time', u'around', u',', u'and', u'her', u'performance', u'is', u'probably', u'the', u'best', u'in', u'this', u'film', u'.', u'michael', u'madsen', u'is', u'so', u'-', u'so', u',', u'but', u'he', u'isn', u\"'\", u't', u'annoying', u',', u'and', u'he', u'soon', u'becomes', u'rather', u'appealing', u'(', u'with', u'his', u'nice', u'cynic', u'personality', u')', u'.', u'james', u'cromwell', u'has', u'a', u'small', u'part', u',', u'but', u'he', u'makes', u'it', u'much', u'better', u'than', u'what', u'it', u'could', u'have', u'been', u'with', u'a', u'more', u'incapable', u'actor', u'.', u'as', u'i', u'say', u',', u'any', u'film', u'with', u'james', u'cromwell', u'dramatically', u'increases', u'in', u'likeability', u'.', u'mykelti', u'williamson', u'gives', u'an', u'enjoyable', u'performance', u',', u'and', u'he', u'gives', u'the', u'film', u'a', u'more', u'down', u'-', u'to', u'-', u'earth', u'feel', u'.', u'and', u',', u'of', u'course', u',', u'justin', u'lazard', u'.', u'lazard', u'has', u'so', u'far', u'been', u'ridiculed', u'for', u'his', u'performance', u',', u'but', u'i', u'think', u'he', u'is', u'effective', u'.', u'sure', u',', u'he', u'is', u'wooden', u',', u'but', u'isn', u\"'\", u't', u'that', u'what', u'his', u'character', u'is', u'like', u'?', u'the', u'moment', u'when', u'he', u'touches', u'the', u'glass', u'separating', u'henstridge', u'from', u'him', u'was', u'extremely', u'well', u'done', u',', u'due', u'to', u'the', u'couple', u\"'\", u's', u'acting', u'.', u'species', u'ii', u'is', u'rated', u'r', u'for', u'strong', u'sexuality', u',', u'sci', u'-', u'fi', u'violence', u'/', u'gore', u'and', u'language', u'.', u'this', u'is', u'definitely', u'an', u'r', u'rated', u'film', u'that', u'young', u'kids', u'should', u'not', u'see', u'.', u'more', u'than', u'likely', u',', u'they', u'would', u'probably', u'have', u'nightmares', u'and', u'never', u'have', u'sex', u'for', u'the', u'rest', u'of', u'their', u'lives', u'.', u'hell', u',', u'i', u'don', u\"'\", u't', u'even', u'know', u'if', u'i', u'will', u'.', u'what', u'is', u'sure', u'to', u'be', u'a', u'critically', u'lambasted', u'film', u'turns', u'out', u'to', u'be', u'the', u'surprise', u'film', u'of', u'the', u'year', u'.', u'i', u'probably', u'won', u\"'\", u't', u'see', u'another', u'film', u'where', u'i', u'was', u'expecting', u'so', u'little', u'and', u'got', u'so', u'much', u'for', u'quite', u'a', u'while', u'.', u'director', u'peter', u'medak', u'has', u'crafted', u'a', u'very', u'suspenseful', u',', u'and', u'sometimes', u'very', u'scary', u'movie', u'out', u'of', u'a', u'mediocre', u'series', u'.', u'medak', u'has', u'also', u'mastered', u'the', u'wonderful', u'\"', u'jump', u'!', u'\"', u'moments', u',', u'and', u'has', u'probably', u'the', u'second', u'scariest', u'moment', u'i', u'have', u'ever', u'seen', u'on', u'film', u'(', u'scream', u'still', u'has', u'the', u'first', u')', u'.', u'strong', u'acting', u',', u'smart', u'dialogue', u',', u'intelligent', u'plotting', u',', u'and', u'a', u'sure', u'-', u'handed', u'director', u',', u'species', u'ii', u'is', u'exactly', u'what', u'these', u'films', u'should', u'be', u':', u'entertaining', u'.'], u'pos')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u',', 77717), (u'the', 76529), (u'.', 65876), (u'a', 38106), (u'and', 35576), (u'of', 34123), (u'to', 31937), (u\"'\", 30585), (u'is', 25195), (u'in', 21822), (u's', 18513), (u'\"', 17612), (u'it', 16107), (u'that', 15924), (u'-', 15595)]\n253\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "print(documents[1])\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))\n",
    "print(all_words[\"stupid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. [Converting words to Features with NLTK](https://pythonprogramming.net/words-as-features-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15355355/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sonja',\n u'askew',\n u'woods',\n u'spiders',\n u'bazooms',\n u'hanging',\n u'francesca',\n u'comically',\n u'localized',\n u'disobeying',\n u'hennings',\n u'canet',\n u'scold',\n u'originality',\n u'caned',\n u'rickman',\n u'slothful',\n u'wracked',\n u'stipulate',\n u'capoeira',\n u'rawhide',\n u'taj',\n u'bringing',\n u'unsworth',\n u'liaisons',\n u'grueling',\n u'sommerset',\n u'wooden',\n u'wednesday',\n u'broiled',\n u'circuitry',\n u'crotch',\n u'elgar',\n u'stereotypical',\n u'shows',\n u'gavan',\n u'rebuilding',\n u'snuggles',\n u'francesco',\n u'feasibility',\n u'miniatures',\n u'gorman',\n u'woody',\n u'consenting',\n u'scraped',\n u'inanimate',\n u'errors',\n u'reopens',\n u'cooking',\n u'fonzie',\n u'opportunists',\n u'islamic',\n u'joely',\n u'designing',\n u'numeral',\n u'succumb',\n u'shocks',\n u'chins',\n u'crooned',\n u'jubilantly',\n u'rocque',\n u'ching',\n u'china',\n u'shandling',\n u'confronts',\n u'wiseguy',\n u'natured',\n u'existentialist',\n u'kids',\n u'uplifting',\n u'controversy',\n u'crowdpleasing',\n u'neurologist',\n u'spotty',\n u'climber',\n u'appropriately',\n u'cobblers',\n u'projection',\n u'outraging',\n u'lengthen',\n u'emerich',\n u'unsinkable',\n u'stern',\n u'kethcum',\n u'dna',\n u'catchy',\n u'insecurity',\n u'cannibal',\n u'sidebars',\n u'music',\n u'therefore',\n u'mystic',\n u'mutinies',\n u'magyuver',\n u'deloreans',\n u'mesmerize',\n u'yahoo',\n u'faceted',\n u'exuberantly',\n u'======',\n u'eggar',\n u'boorman',\n u'foregrounds',\n u'primeval',\n u'voicework',\n u'circumstances',\n u'reingold',\n u'morally',\n u'locked',\n u'daqughter',\n u'locker',\n u'locket',\n u'soundbite',\n u'gershon',\n u'tomahawk',\n u'matilda',\n u'wang',\n u'wane',\n u'unjust',\n u'pooper',\n u'dishearteningly',\n u'want',\n u'pinto',\n u'absolute',\n u'vicent',\n u'beyer',\n u'travel',\n u'copious',\n u'playback',\n u'dangerfield',\n u'dared',\n u'prostitues',\n u'cadence',\n u'thivisol',\n u'sonorra',\n u'dinosaurs',\n u'wrong',\n u'cerebrally',\n u'sentencing',\n u'domed',\n u'colorfully',\n u'glenne',\n u'recombination',\n u'subplots',\n u'sickening',\n u'tulip',\n u'18th',\n u'perpetrator',\n u'crackin',\n u'nonsensical',\n u'romper',\n u'disengaging',\n u'snugly',\n u'kuei',\n u'welcomed',\n u'concurrence',\n u'stoicism',\n u'whizzing',\n u'dethroned',\n u'sidekicks',\n u'rewarded',\n u'welcomes',\n u'hypnotist',\n u'wickedly',\n u'fit',\n u'lifeline',\n u'screaming',\n u'fix',\n u'_i_know_what_you_did_last_summer_',\n u'fig',\n u'wales',\n u'bunker',\n u'fin',\n u'zucker',\n u'songwriter',\n u'municipality',\n u'recollections',\n u'guiler',\n u'effects',\n u'multidimensional',\n u'sixteen',\n u'undeveloped',\n u'saddened',\n u'whacking',\n u'bartok',\n u'barton',\n u'foregin',\n u'sugarplums',\n u'frewer',\n u'arrow',\n u'ingrid',\n u'_eve',\n u'windmill',\n u'telescope',\n u'allah',\n u'allan',\n u'parasites',\n u'touts',\n u'oprah',\n u'smirk',\n u'scrumptiously',\n u'indiscretion',\n u'nordoff',\n u'mason',\n u'encourage',\n u'adapt',\n u'zellwegger',\n u'outburst',\n u'abbott',\n u'stamping',\n u'abbots',\n u'anonymously',\n u'beristain',\n u'pumpkins',\n u'corrects',\n u'estimate',\n u'universally',\n u'chlorine',\n u'jugs',\n u'reiser',\n u'sickeningly',\n u'mackey',\n u'disturbed',\n u'competed',\n u'dentures',\n u'loudness',\n u'wiseguys',\n u'juergen',\n u'disfigured',\n u'stylistics',\n u'kfc',\n u'megabytes',\n u'sooty',\n u'davidovitch',\n u'olds',\n u'renovated',\n u'service',\n u'forrester',\n u'corsucant',\n u'reuben',\n u'needed',\n u'master',\n u'_2001_',\n u'critter',\n u'genesis',\n u'weendigo',\n u'caitlyn',\n u'rewards',\n u'enthrall',\n u'oingo',\n u'doreen',\n u'mutilated',\n u'lyndon',\n u'positively',\n u'ahmed',\n u'bannister',\n u'handcuffs',\n u'meditative',\n u'idly',\n u'idle',\n u'exclaimed',\n u'friend',\n u'feeling',\n u'longs',\n u'sustaining',\n u'spectrum',\n u'longo',\n u'coachmen',\n u'arousal',\n u'urinate',\n u'dozen',\n u'affairs',\n u'wholesome',\n u'courier',\n u'portillo',\n u'uncouth',\n u'racers',\n u'toothed',\n u'workmates',\n u'shipments',\n u'committing',\n u'limitless',\n u'diminishing',\n u'vexing',\n u'cinematic',\n u'resonates',\n u'disjointed',\n u'mouth',\n u'reverence',\n u'resonated',\n u'expound',\n u'singer',\n u'multiracial',\n u'tech',\n u'fugitives',\n u'keeble',\n u'rayden',\n u'scream',\n u'saying',\n u'teresa',\n u'loitered',\n u'padded',\n u'ulcer',\n u'tempted',\n u'cheaply',\n u'thai',\n u'hounded',\n u'orleans',\n u'clicked',\n u'rico',\n u'bliss',\n u'rick',\n u'rich',\n u'rice',\n u'rica',\n u'plate',\n u'remaning',\n u'videodrome',\n u'outfielders',\n u'plath',\n u'platt',\n u'clumsiness',\n u'altogether',\n u'chyron',\n u'droning',\n u'stoically',\n u'nicely',\n u'boarder',\n u'pretzel',\n u'patch',\n u'eyelids',\n u'dodie',\n u'boarded',\n u'jovivich',\n u'heirloom',\n u'clarified',\n u'sensitivity',\n u'pinon',\n u'slashfest',\n u'48th',\n u'playfulness',\n u'deadpan',\n u'irs',\n u'droves',\n u'bandaras',\n u'ira',\n u'ire',\n u'wage',\n u'dethrones',\n u'extend',\n u'nature',\n u'lapping',\n u'extent',\n u'reacquaints',\n u'tyranny',\n u'benigness',\n u'veer',\n u'voyeuristic',\n u'himalayas',\n u'incense',\n u'fruity',\n u'lookin',\n u'melinda',\n u'fearlessly',\n u'eradicate',\n u'zigged',\n u'rehash',\n u'mortified',\n u'maclaine',\n u'gopher',\n u'gypsies',\n u'fondled',\n u'charnel',\n u'affiliated',\n u'surname',\n u'blonde',\n u'underdone',\n u'milquetoast',\n u'marshmallows',\n u'union',\n u'fro',\n u'studious',\n u'.',\n u'muck',\n u'much',\n u'wyman',\n u'tonino',\n u'fry',\n u'toning',\n u'ocious',\n u'obese',\n u'premier',\n u'retrospect',\n u'spit',\n u'arkin',\n u'freehold',\n u'almasy',\n u'boardroom',\n u'dave',\n u'yugoslavians',\n u'doubts',\n u'spin',\n u'professionally',\n u'paraglider',\n u'employ',\n u'nfeatured',\n u'misconstrued',\n u'prostrate',\n u'k',\n u'canoeing',\n u'ditching',\n u'verges',\n u'lackies',\n u'mirabella',\n u'eighteen',\n u'haplessly',\n u'oxymoron',\n u'breakfast',\n u'hone',\n u'protovision',\n u'hong',\n u'emmylou',\n u'inventively',\n u'portobello',\n u'remand',\n u'mummified',\n u'honk',\n u'spews',\n u'split',\n u'codename',\n u'principals',\n u'cavanaugh',\n u'boiled',\n u'effortlessly',\n u'issac',\n u'frenchmen',\n u'vivien',\n u'torpedoes',\n u'marched',\n u'buliwyf',\n u'boiler',\n u'rulebook',\n u'featherweight',\n u'wcw',\n u'noblewoman',\n u'mentors',\n u'academic',\n u'stillness',\n u'academia',\n u'goofing',\n u'odile',\n u'waitering',\n u'corporate',\n u'massaging',\n u'falstaff',\n u'gigolo',\n u'belloq',\n u'absurdities',\n u'golden',\n u'bacri',\n u'_would_',\n u'homogeneity',\n u'snickered',\n u'boondocks',\n u'portrayed',\n u'lasso',\n u'hai',\n u'hal',\n u'ham',\n u'han',\n u'hab',\n u'espouses',\n u'had',\n u'insubordination',\n u'hag',\n u'hay',\n u'mcnamara',\n u'beloved',\n u'hap',\n u'har',\n u'has',\n u'hat',\n u'preciously',\n u'hav',\n u'haw',\n u'elders',\n u'survival',\n u'unequivocally',\n u'otherworldly',\n u'indicative',\n u'shadow',\n u'flotsam',\n u'ballhaus',\n u'sleuthing',\n u'delectably',\n u'alice',\n u'noteables',\n u'festivities',\n u'misdemeanors',\n u'unabashedly',\n u'attorney',\n u'crowd',\n u'crowe',\n u'czech',\n u'mosques',\n u'crown',\n u'topping',\n u'deflection',\n u'captive',\n u'beatng',\n u'billboard',\n u'namuth',\n u'pesimism',\n u'bottom',\n u'chabert',\n u'inhuman',\n u'plucked',\n u'crookier',\n u'monogamy',\n u'seagrave',\n u'subkoff',\n u'unequipped',\n u'rooker',\n u'barcode',\n u'eduard',\n u'starring',\n u'mediocrity',\n u'disdains',\n u'bamboo',\n u'stoker',\n u'caraciture',\n u'restlessness',\n u'benches',\n u'filmcritic',\n u'bicentennial',\n u'oneness',\n u'mussenden',\n u'stoked',\n u'whoaaaaaa',\n u'kilgore',\n u'dahlings',\n u'maxwell',\n u'marshall',\n u'honeymoon',\n u'mba',\n u'liebes',\n u'beings',\n u'marshals',\n u'hallucinogenic',\n u'shoots',\n u'aggressivelly',\n u'despised',\n u'fabric',\n u'_people_',\n u'suffice',\n u'raped',\n u'grasping',\n u'despises',\n u'greatness',\n u'rapes',\n u'grooms',\n u'spurting',\n u'ballisitic',\n u'congratulations',\n u'hypsy',\n u'humbled',\n u'mat',\n u'masquerading',\n u'wacked',\n u'smashes',\n u'1600s',\n u'humbler',\n u'complications',\n u'smashed',\n u'duet',\n u'dues',\n u'passenger',\n u'disgrace',\n u'barrymore',\n u'minah',\n u'unnerve',\n u'yankovich',\n u'decapitation',\n u'paperwork',\n u'triangles',\n u'slurring',\n u'spacemusic',\n u'biederman',\n u'dowling',\n u'cambodia',\n u'rioters',\n u'pasadena',\n u'role',\n u'obliges',\n u'rolf',\n u'wreaked',\n u'vegetative',\n u'wordlessly',\n u'roll',\n u'spielbergization',\n u'intend',\n u'palms',\n u'slaver',\n u'transported',\n u'palme',\n u'comely',\n u'intent',\n u'smelling',\n u'variable',\n u'batmans',\n u'hawkes',\n u'explosions',\n u'loren',\n u'meteorologist',\n u'shootout',\n u'innuendos',\n u'overturned',\n u'gown',\n u'childs',\n u'cincinnati',\n u'chain',\n u'whoever',\n u'diggler',\n u'bandits',\n u'chair',\n u'macht',\n u'ballet',\n u'malintentioned',\n u'grapples',\n u'pell',\n u'afi',\n u'freelance',\n u'crates',\n u'crater',\n u'silencers',\n u'underlining',\n u'overpopulated',\n u'obssessed',\n u'macho',\n u'oversight',\n u'tenacious',\n u'downloading',\n u'paychecks',\n u'jerk',\n u'tastefully',\n u'jere',\n u'prancer',\n u'prances',\n u'choice',\n u'metamorphoses',\n u'embark',\n u'gloomy',\n u'ghostbusters',\n u'stays',\n u'exact',\n u'minute',\n u'cooks',\n u'masturbates',\n u'minnie',\n u'skewed',\n u'skewer',\n u'xenophobe',\n u'dialogueless',\n u'trails',\n u'copyrighted',\n u'heavyweight',\n u'chopping',\n u'shirts',\n u'ogled',\n u'headset',\n u'lavishness',\n u'massironi',\n u'antwerp',\n u'celebrated',\n u'wayward',\n u'geography',\n u'celebrates',\n u'unintentionally',\n u'drafted',\n u'oldies',\n u'climbs',\n u'blunted',\n u'topicality',\n u'gladys',\n u'address',\n u'reclining',\n u'dwindling',\n u'benson',\n u'mafioso',\n u'plunges',\n u'accomplishes',\n u'dusty',\n u'impacted',\n u'cusack',\n u'accomplished',\n u'sprouted',\n u'expressively',\n u'enrols',\n u'influx',\n u'kasinsky',\n u'houseman',\n u'betraying',\n u'fakery',\n u'red',\n u'darnell',\n u'undergone',\n u'working',\n u'goregeous',\n u'oldham',\n u'opposed',\n u'portorican',\n u'familar',\n u'perishes',\n u'ooooooo',\n u'israel',\n u'assimilation',\n u'sierra',\n u'consoles',\n u'riders',\n u'rebounding',\n u'titanium',\n u'originally',\n u'abortion',\n u'americanised',\n u'harmonious',\n u'goody',\n u'following',\n u'zippers',\n u'admired',\n u'mirrors',\n u'stetson',\n u'parachute',\n u'locks',\n u'sextette',\n u'admires',\n u'admirer',\n u'listens',\n u'septic',\n u'vainly',\n u'thanking',\n u'edouard',\n u'maude',\n u'rewatched',\n u'mintues',\n u'casualness',\n u'mythos',\n u'convincingly',\n u'fueled',\n u'meddled',\n u'commensurately',\n u'brainless',\n u'egotistical',\n u'surfing',\n u'jonnie',\n u'conscious',\n u'regressive',\n u'nebbish',\n u'skirmish',\n u'wolves',\n u'pulled',\n u'manga',\n u'impactful',\n u'years',\n u'professors',\n u'structuring',\n u'episodes',\n u'kyzynski',\n u'professory',\n u'overlord',\n u'disconnect',\n u'slimeball',\n u'jia',\n u'milked',\n u'jim',\n u'troubles',\n u'rudnick',\n u'wahlberg',\n u'jip',\n u'suspension',\n u'troubled',\n u'modestly',\n u'recipients',\n u'civilian',\n u'courageously',\n u'indigenous',\n u'overpowering',\n u'drilling',\n u'workmanlike',\n u'henpecked',\n u'sorted',\n u'\\\\',\n u'materialized',\n u'didn',\n u'didi',\n u'dispite',\n u'fisherman',\n u'battleships',\n u'instability',\n u'quarter',\n u'greenwald',\n u'quartet',\n u'materializes',\n u'retrieve',\n u'bursting',\n u'receipt',\n u'remembrance',\n u'sponsor',\n u'entering',\n u'salads',\n u'disasters',\n u'bouyant',\n u'interned',\n u'yojimbo',\n u'disaster_',\n u'seriously',\n u'trauma',\n u'firorina',\n u'internet',\n u'merpeople',\n u'henreid',\n u'igniting',\n u'realisation',\n u'complicates',\n u'disintegrated',\n u'hairdresser',\n u'complicated',\n u'grandma',\n u'marla',\n u'modest',\n u'marlo',\n u'initiate',\n u'aboard',\n u'socking',\n u'neglect',\n u'emotion',\n u'gunshot',\n u'tingles',\n u'saving',\n u'symmetry',\n u'spoken',\n u'velda',\n u'savini',\n u'westlake',\n u'reprisal',\n u'one',\n u'ony',\n u'punishable',\n u'periodical',\n u'haviland',\n u'tamara',\n u'onw',\n u'plotless',\n u'exaggerations',\n u'stifler',\n u'stifles',\n u'formulates',\n u'limburgher',\n u'stifled',\n u'hurricaine',\n u'oversimplified',\n u'lingering',\n u'featherbrained',\n u'beesley',\n u'cherbourg',\n u'shawn',\n u'surges',\n u'snatch',\n u'devito',\n u'anthesis',\n u'absorbs',\n u'rza',\n u'hoyle',\n u'gisbourne',\n u'farsical',\n u'crossroads',\n u'admitedly',\n u'rehab',\n u'wandering',\n u'disasterous',\n u'dilemnas',\n u'bulow',\n u'illness',\n u'aaaaaaaahhhh',\n u'stylings',\n u'sumptuous',\n u'turned',\n u'locations',\n u'jewels',\n u'balsan',\n u'uninterrupted',\n u'turner',\n u'politicos',\n u'invite',\n u'pimply',\n u'zoe',\n u'cigarettes',\n u'warriors',\n u'zoo',\n u'goodman',\n u'portents',\n u'martineau',\n u'_titus_andronicus_',\n u'mayer',\n u'lick',\n u'pimple',\n u'murphy',\n u'opposite',\n u'discerning',\n u'spewing',\n u'buffet',\n u'printed',\n u'knowingly',\n u'buffed',\n u'huns',\n u'captivatingly',\n u'touchy',\n u'phil',\n u'toucha',\n u'jitters',\n u'messier',\n u'jittery',\n u'lydia',\n u'feuds',\n u'delroy',\n u'wynn',\n u'fakeouts',\n u'imagines',\n u'friction',\n u'fecal',\n u'oderkerk',\n u'inconsistent',\n u'soviets',\n u'imagined',\n u'wynt',\n u'seminal',\n u'zahn',\n u'reconciling',\n u'coaxing',\n u'remastered',\n u'guarded',\n u'rejoiced',\n u'suitcases',\n u'revolutionized',\n u'tilting',\n u'simplistic',\n u'awaiting',\n u'matsumoto',\n u'pimp',\n u'trys',\n u'carrion',\n u'spam',\n u'recoiling',\n u'choudhury',\n u'vision',\n u'morose',\n u'attenuated',\n u'underbids',\n u'audaciously',\n u'impressions',\n u'intoxicating',\n u'aboslutely',\n u'defensively',\n u'retells',\n u'masturbatory',\n u'alarming',\n u'sponsorship',\n u'moons',\n u'enjoys',\n u'playhouse',\n u'caan',\n u'tsui',\n u'lyricized',\n u'tamahori',\n u'braggarts',\n u'punts',\n u'awards',\n u'menacing',\n u'uncharacteristically',\n u'concentrated',\n u'busting',\n u'majestically',\n u'rhodes',\n u'matheson',\n u'millionaire',\n u'flipped',\n u'policed',\n u's',\n u'workplace',\n u'concentrates',\n u'flipper',\n u'doctoring',\n u'loveliest',\n u'beowolf',\n u'anette',\n u'comparitive',\n u'collides',\n u'west',\n u'deuteronomy',\n u'collided',\n u'motives',\n ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'clamoring': False, u'madsen': False, u'sonja': False, u'unsworth': False, u'woods': False, u'spiders': False, u'gavan': False, u'francesco': False, u'francesca': False, u'fedoore': False, u'comically': False, u'negg': False, u'localized': False, u'stinks': False, u'disobeying': False, u'hennings': False, u'porno': False, u'canet': False, u'giacomo': False, u'stinky': False, u'scold': False, u'originality': False, u'neighbours': False, u'caned': False, u'rickman': False, u'worth': False, u'porns': False, u'alternating': False, u'amorous': False, u'copasetic': False, u'slothful': False, u'wracked': False, u'dougnac': False, u'aurora': False, u'stipulate': False, u'kissed_': False, u'helgenberger': False, u'capoeira': False, u'rosalba': False, u'crackin': False, u'rawhide': False, u'summarized': False, u'waterlogged': False, u'screaming': False, u'yikes': False, u'recollections': False, u'liaisons': False, u'grueling': False, u'sommerset': False, u'investigator': False, u'wooden': False, u'wednesday': False, u'broiled': False, u'samurai': False, u'circuitry': False, u'notifying': False, u'crotch': False, u'elgar': False, u'errol': False, u'stereotypical': False, u'monologue': False, u'shows': True, u'roldan': False, u'jamaica': False, u'bazooms': False, u'sabbato': False, u'snuggles': False, u'hanging': False, u'pescara': False, u'feasibility': False, u'miniatures': False, u'nerdiest': False, u'mesmerising': False, u'gorman': False, u'woody': False, u'consenting': False, u'scraped': False, u'gazon': False, u'machines': False, u'inanimate': False, u'errors': False, u'euclidean': False, u'rekindle': False, u'offshoots': False, u'cooking': False, u'fonzie': False, u'opportunists': False, u'petri': False, u'videodrome': False, u'outfielders': False, u'numeral': False, u'succumb': False, u'shocks': False, u'personifies': False, u'viewings': False, u'chins': False, u'crooned': False, u'jubilantly': False, u'rocque': False, u'spunky': False, u'dilapidating': False, u'equals': False, u'metaphorically': False, u'boyum': False, u'ching': False, u'protection': False, u'china': False, u'personified': False, u'dobie': False, u'shandling': False, u'wiseguy': False, u'natured': False, u'watermelons': False, u'kids': True, u'uplifting': False, u'k': False, u'controversy': False, u'rebhorn': False, u'crowdpleasing': False, u'stressed': False, u'neurologist': False, u'bunker': False, u'spotty': False, u'climber': False, u'appropriately': False, u'cobblers': False, u'projection': False, u'urbaniak': False, u'outraging': False, u'brs': False, u'lengthen': False, u'emerich': False, u'flotsam': False, u'bro': False, u'lavatory': False, u'archaeological': False, u'unsinkable': False, u'stern': False, u'compulsively': False, u'namuth': False, u'kethcum': False, u'sarah': False, u'plot': True, u'plow': False, u'dna': False, u'plop': False, u'catchy': False, u'insecurity': False, u'sweater': False, u'coins': False, u'ploy': False, u'cannibal': False, u'sidebars': False, u'_people_': False, u'music': True, u'therefore': False, u'superweapons': False, u'mutinies': False, u'administering': False, u'magyuver': False, u'separated': False, u'deloreans': False, u'bombast': False, u'paperwork': False, u'kohn': False, u'mesmerize': False, u'ascribe': False, u'yahoo': False, u'exuberantly': False, u'======': False, u'championships': False, u'boorman': False, u'diggler': False, u'provide': False, u'foregrounds': False, u'primeval': False, u'conditioned': False, u'voicework': False, u'blocking': False, u'circumstances': False, u'reingold': False, u'tastefully': False, u'1993': False, u'morally': False, u'locked': False, u'1994': False, u'daqughter': False, u'1996': False, u'1999': False, u'1998': False, u'overpowers': False, u'cuddly': False, u'divorces': False, u'locker': False, u'tissue': False, u'locket': False, u'era': False, u'soundbite': False, u'gershon': False, u'elbow': False, u'erm': False, u'ern': False, u'plunges': False, u'recipes': False, u'scripting': False, u'matilda': False, u'wang': False, u'indicated': False, u'wane': False, u'portorican': False, u'flung': False, u'winnfield': False, u'heartless': False, u'strangelove': False, u'titanium': False, u'dishearteningly': False, u'want': True, u'repressiveness': False, u'pinto': False, u'absolute': False, u'impassive': False, u'skyler': False, u'vicent': False, u'beyer': False, u'travel': False, u'nuts': False, u'copious': False, u'kyzynski': False, u'recovers': False, u'playback': False, u'dangerfield': False, u'conn': False, u'moron': False, u'titillate': False, u'prostitues': False, u'truthful': False, u'cadence': False, u'thivisol': False, u'sonorra': False, u'sordidness': False, u'henreid': False, u'memorial': False, u'customs': False, u'millimeter': False, u'dinosaurs': False, u'wrong': False, u'aurore': False, u'ladden': False, u'cerebrally': False, u'sentencing': False, u'dumbo': False, u'greediness': False, u'arch': False, u'foundering': False, u'hurricaine': False, u'complacent': False, u'colorfully': False, u'elusive': False, u'glenne': False, u'alienate': False, u'recombination': False, u'schneider': False, u'appreciate': False, u'americanization': False, u'subplots': False, u'purging': False, u'sickening': False, u'tulip': False, u'18th': False, u'davies': False, u'moroder': False, u'nonsensical': False, u'romper': False, u'disengaging': False, u'droagon': False, u'_american_psycho_': False, u'leeanne': False, u'snugly': False, u'gumption': False, u'kuei': False, u'scalding': False, u'welcomed': False, u'matewan': False, u'concurrence': False, u'stoicism': False, u'whizzing': False, u'wachowskis': False, u'matsumoto': False, u'sidekicks': False, u'vito': False, u'innovative': False, u'rewarded': False, u'welcomes': False, u'understates': False, u'wickedly': False, u'fit': False, u'lifeline': False, u'bringing': False, u'fix': False, u'christie': False, u'_i_know_what_you_did_last_summer_': False, u'trager': False, u'production': True, u'understated': False, u'fig': False, u'valor': False, u'wales': False, u'fin': False, u'travellers': False, u'vamires': False, u'soundbites': False, u'songwriter': False, u'municipality': False, u'locusts': False, u'safe': False, u'inhereit': False, u'collide': False, u'laconically': False, u'expressionist': False, u'roommate': False, u'guiler': False, u'effects': False, u'expressionism': False, u'cohagen': False, u'multidimensional': False, u'sixteen': False, u'undeveloped': False, u'saddened': False, u'aneeka': False, u'petrovsky': False, u'defeaningly': False, u'progression': False, u'dingo': False, u'whacking': False, u'bartok': False, u'reasonably': False, u'routines': False, u'barton': False, u'l': False, u'foregin': False, u'dingy': False, u'sugarplums': False, u'nighthawks': False, u'frewer': False, u'averse': False, u'ingrid': False, u'fearsomely': False, u'feeds': False, u'_eve': False, u'overpopulated': False, u'telescope': False, u'dumping': False, u'masseuse': False, u'allah': False, u'allan': False, u'sled': False, u'parasites': False, u'maniacs': False, u'tragicomic': False, u'slew': False, u'roadblock': False, u'inadvertently': False, u'touts': False, u'oprah': False, u'smirk': False, u'scrumptiously': False, u'indiscretion': False, u'maduro': False, u'nordoff': False, u'danforth': False, u'mason': False, u'encourage': False, u'daniel': False, u'adapt': False, u'uuuhhmmm': False, u'confections': False, u'zellwegger': False, u'judith': False, u'outburst': False, u'mullen': False, u'abbott': False, u'stamping': False, u'meatier': False, u'abbots': False, u'barrier': False, u'colorless': False, u'leftovers': False, u'beristain': False, u'pumpkins': False, u'corrects': False, u'forcibly': False, u'crowned': False, u'estimate': False, u'universally': False, u'chlorine': False, u'renee': False, u'chortled': False, u'dammit': False, u'birdie': False, u'r2': False, u'sickeningly': False, u'refugee': False, u'flawless': False, u'renew': False, u'disturbed': False, u'competed': False, u'dentures': False, u'loudness': False, u'footsteps': False, u'juergen': False, u'haunted': False, u'render': False, u'elmo': False, u'disfigured': False, u'railroads': False, u'immolation': False, u'procreate': False, u'dog_': False, u'stylistics': False, u'kfc': False, u'megabytes': False, u'antarctic': False, u'electronic': False, u'mojo': False, u'sooty': False, u'timothy': False, u'olds': False, u'renovated': False, u'service': False, u'forrester': False, u'2058': False, u'corsucant': False, u'ingen': False, u'reuben': False, u'approximately': False, u'needed': False, u'blurts': False, u'master': False, u'_2001_': False, u'cassavetes': False, u'mistic': False, u'critter': False, u'john': False, u'genesis': False, u'weendigo': False, u'caitlyn': False, u'rewards': False, u'paltry': False, u'enthrall': False, u'offhand': False, u'oingo': False, u'lunges': False, u'waster': False, u'wastes': False, u'scorpions': False, u'mutilated': False, u'enmeshed': False, u'cereal': False, u'wasted': False, u'downtime': False, u'anachronisms': False, u'positively': False, u'ahmed': False, u'reclining': False, u'guile': False, u'bannister': False, u'roelfs': False, u'handcuffs': False, u'idly': False, u'project': False, u'idle': False, u'exclaimed': False, u'guilt': False, u'friend': False, u'historical': False, u'apparantly': False, u'feeling': True, u'seminal': False, u'humble': False, u'rouen': False, u'tautness': False, u'longs': False, u'portraits': False, u'sustaining': False, u'flavorful': False, u'spectrum': False, u'enchanted': False, u'longo': False, u'refreshingly': False, u'arousal': False, u'tenuous': False, u'urinate': False, u'contents': False, u'dozen': False, u'affairs': False, u'wholesome': False, u'courier': False, u'scumbagginess': False, u'cronenberg': False, u'convenient': False, u'uncouth': False, u'gripe': False, u'saunder': False, u'racers': False, u'toothed': False, u'subjects': False, u'nuez': False, u'thundering': False, u'pilgrimage': False, u'workmates': False, u'enervation': False, u'shipments': False, u'gravy': False, u'germann': False, u'committing': False, u'bruce': False, u'limitless': False, u'diminishing': False, u'vexing': False, u'cinematic': False, u'resonates': False, u'ramblings': False, u'disjointed': False, u'stardom': False, u'mouth': False, u'culminates': False, u'reverence': False, u'scripts': False, u'resonated': False, u'parting': False, u'expound': False, u'singer': False, u'macfadyen': False, u'bracken': False, u'dubarry': False, u'musical': False, u'multiracial': False, u'swamp': False, u'bracket': False, u'tech': False, u'fugitives': False, u'keeble': False, u'rayden': False, u'rhythmless': False, u'brinkford': False, u'germany': False, u'scream': False, u'crowbar': False, u'saying': False, u'rockies': False, u'overdoes': False, u'stephens': False, u'lewis': False, u'teresa': False, u'loitered': False, u'rosselini': False, u'padded': False, u'bellow': False, u'disturbs': False, u'ulcer': False, u'alferd': False, u'tempted': False, u'cheaply': False, u'councilmembers': False, u'hounded': False, u'capitol': False, u'orleans': False, u'geyser': False, u'clicked': False, u'quaint': False, u'nullifies': False, u'grosbard': False, u'rico': False, u'bliss': False, u'rick': False, u'rich': False, u'rice': False, u'nullified': False, u'rectangle': False, u'rica': False, u'plate': False, u'cappuccino': False, u'joely': False, u'tramell': False, u'belaboured': False, u'chaney': False, u'uncountable': False, u'designing': False, u'plath': False, u'psychiatric': False, u'wisecracks': False, u'platt': False, u'clumsiness': False, u'roundabout': False, u'altogether': False, u'chyron': False, u'vividly': False, u'beleive': False, u'droning': False, u'vicariously': False, u'runs': False, u'stoically': False, u'plotholia': False, u'spilling': False, u'nicely': False, u'boarder': False, u'pretzel': False, u'patch': False, u'eyelids': False, u'rahad': False, u'rune': False, u'gears': False, u'rung': False, u'krupa': False, u'boarded': False, u'scrubbed': False, u'secretary': False, u'jovivich': False, u'heirloom': False, u'clarified': False, u'claymation': False, u'sensitivity': False, u'pinon': False, u'slashfest': False, u'horrendous': False, u'discussions': False, u'optimum': False, u'hairbrush': False, u'techniques': False, u'pastel': False, u'48th': False, u'playfulness': False, u'pressured': False, u'deadpan': False, u'pasted': False, u'away': True, u'irs': False, u'droves': False, u'bandaras': False, u'collette': False, u'bracing': False, u'arcane': False, u'arcand': False, u'meditative': False, u'ira': False, u'drawl': False, u'encounters': False, u'ire': False, u'huison': False, u'extend': False, u'nature': False, u'handful': False, u'lapping': False, u'transylvanians': False, u'diesl': False, u'taraji': False, u'gays': False, u'succumbs': False, u'extent': False, u'beelzebub': False, u'reacquaints': False, u'kitchen': False, u'tyranny': False, u'climate': False, u'benigness': False, u'psychologists': False, u'dorff': False, u'veer': False, u'disdain': False, u'voyeuristic': False, u'himalayas': False, u'compton': False, u'askew': False, u'hollywoodization': False, u'lookin': False, u'disappears': False, u'fearlessly': False, u'eradicate': False, u'zigged': False, u'rehash': False, u'mortified': False, u'tone': False, u'maclaine': False, u'murtaugh': False, u'upbeats': False, u'sobchak': False, u'gopher': False, u'gypsies': False, u'fondled': False, u'charnel': False, u'lick': False, u'affiliated': False, u'tony': False, u'surname': False, u'blonde': False, u'telecommunications': False, u'priscilla': False, u'underdone': False, u'milquetoast': False, u'wright': False, u'union': False, u'fro': False, u'resemblances': False, u'.': True, u'muck': False, u'polemic': False, u'much': False, u'wyman': False, u'noel': False, u'tonino': False, u'kanoby': False, u'fry': False, u'toning': False, u'ocious': False, u'obese': False, u'superpowers': False, u'retrospect': False, u'spit': False, u'attacked': False, u'arkin': False, u'excite': False, u'freehold': False, u'almasy': False, u'psychically': False, u'comprehensible': False, u'dave': False, u'yugoslavians': False, u'doubts': False, u'clairvoyant': False, u'spin': False, u'takaaki': False, u'diverted': False, u'righteous': False, u'espoused': False, u'professionally': False, u'paraglider': False, u'employ': False, u'nfeatured': False, u'misconstrued': False, u'thrash': False, u'prostrate': False, u'35th': False, u'characterizing': False, u'blackly': False, u'cont': False, u'krays': False, u'canoeing': False, u'beetles': False, u'ditching': False, u'verges': False, u'lackies': False, u'separatist': False, u'tylenol': False, u'mirabella': False, u'eighteen': False, u'cong': False, u'haplessly': False, u'voges': False, u'oxymoron': False, u'turner': False, u'sever': False, u'hone': False, u'protovision': False, u'hong': False, u'inventively': False, u'portobello': False, u'remand': False, u'mummified': False, u'amount': False, u'honk': False, u'writerly': False, u'spews': False, u'alevey': False, u'split': False, u'synch': False, u'mindfuck': False, u'codename': False, u'principals': False, u'cavanaugh': False, u'wheel': False, u'boiled': False, u'effortlessly': False, u'fuss': False, u'issac': False, u'frenchmen': False, u'hana': False, u'vivien': False, u'torpedoes': False, u'lyndon': False, u'bening': False, u'liberties': False, u'marched': False, u'buliwyf': False, u'boiler': False, u'dashing': False, u'rulebook': False, u'hans': False, u'selfless': False, u'brainers': False, u'featherweight': False, u'postponed': False, u'whereby': False, u'noblewoman': False, u'1600': False, u'fashionable': False, u'mentors': False, u'academic': False, u'stillness': False, u'academia': False, u'goofing': False, u'humbly': False, u'sullenly': False, u'waitering': False, u'corporate': False, u'massaging': False, u'pronouncements': False, u'gigolo': False, u'solaris': False, u'belloq': False, u'absurdities': False, u'golden': False, u'vying': False, u'newton': False, u'_would_': False, u'homogeneity': False, u'snickered': False, u'sabbatical': False, u'ol': False, u'portrayed': False, u'electronically': False, u'lasso': False, u'hai': False, u'denton': False, u'designers': False, u'hal': False, u'ham': False, u'han': False, u'cornell': False, u'similarities': False, u'hab': False, u'espouses': False, u'had': False, u'insubordination': False, u'hag': False, u'jost': False, u'hay': False, u'mcnamara': False, u'cognac': False, u'beloved': False, u'joss': False, u'hap': False, u'har': False, u'has': True, u'hat': False, u'preciously': False, u'hav': False, u'haw': False, u'packin': False, u'insensitive': False, u'elders': False, u'survival': False, u'tricking': False, u'inflicting': False, u'unequivocally': False, u'otherworldly': False, u'indicative': False, u'everton': False, u'shadow': False, u'vapors': False, u'unfounded': False, u'ballhaus': False, u'hairless': False, u'sleuthing': False, u'eroded': False, u'arcs': False, u'deviance': False, u'cooler': False, u'huns': False, u'alice': False, u'noteables': False, u'festivities': False, u'sorvino': False, u'homing': False, u'night': False, u'revisiting': False, u'grotesquely': False, u'cooled': False, u'misdemeanors': False, u'unabashedly': False, u'attorney': False, u'dimitri': False, u'crowd': False, u'crowe': False, u'czech': False, u'flatter': False, u'mosques': False, u'crown': False, u'hypsy': False, u'deflection': False, u'changwei': False, u'captive': False, u'couture': False, u'stardust': False, u'flatten': False, u'kieslowski': False, u'billboard': False, u'bore': False, u'confusing': True, u'adorably': False, u'congratulate': False, u'born': False, u'wiseacre': False, u'bottom': True, u'chabert': False, u'inhuman': False, u'plucked': False, u'asking': False, u'absolution': False, u'lahore': False, u'melange': False, u'monogamy': False, u'seagrave': False, u'participation': False, u'subkoff': False, u'unequipped': False, u'peek': False, u'rooker': False, u'peel': False, u'sadie': False, u'elucidate': False, u'barcode': False, u'shogun': False, u'eduard': False, u'starring': False, u'tribes': False, u'peer': False, u'guild': False, u'peep': False, u'disdains': False, u'explainable': False, u'peet': False, u'menage': False, u'stoker': False, u'deathless': False, u'ferraris': False, u'caraciture': False, u'restlessness': False, u'benches': False, u'_____': False, u'filmcritic': False, u'bicentennial': False, u'oneness': False, u'mussenden': False, u'janitorial': False, u'hoenicker': False, u'stoked': False, u'whoaaaaaa': False, u'kilgore': False, u'gads': False, u'dahlings': False, u'jacques': False, u'guiness': False, u'8034': False, u'wasting': False, u'maxwell': False, u'marshall': False, u'honeymoon': False, u'profession': False, u'mba': False, u'liebes': False, u'rendering': False, u'beings': False, u'marshals': False, u'hallucinogenic': False, u'shoots': False, u'aggressivelly': False, u'stumble': False, u'familiarize': False, u'despised': False, u'deception': False, u'fabric': False, u'plod': False, u'suffice': False, u'unfocused': False, u'raped': False, u'grasping': False, u'despises': False, u'obserable': False, u'greatness': False, u'rapes': False, u'exacty': False, u'grooms': False, u'spurting': False, u'overjoyed': False, u'ballisitic': False, u'needles': False, u'catalyst': False, u'congratulations': False, u'humbled': False, u'masquerading': False, u'smashes': False, u'1600s': False, u'humbler': False, u'complications': False, u'exacts': False, u'smashed': False, u'verging': False, u'duet': False, u'dues': False, u'passenger': False, u'ayla': False, u'disgrace': False, u'barrymore': False, u'minah': False, u'unnerve': False, u'yankovich': False, u'borg': False, u'decapitation': False, u'paglia': False, u'triangles': False, u'slurring': False, u'spacemusic': False, u'biederman': False, u'dowling': False, u'cambodia': False, u'fuse': False, u'pasadena': False, u'role': False, u'telefixated': False, u'rolf': False, u'vegetative': False, u'wordlessly': False, u'roll': False, u'intend': False, u'palms': False, u'transported': False, u'palme': False, u'connote': False, u'comely': False, u'intent': False, u'smelling': False, u'variable': False, u'batmans': False, u'bacri': False, u'hawkes': False, u'explosions': False, u'loren': False, u'meteorologist': False, u'shootout': False, u'overturned': False, u'gown': False, u'hyperdrive': False, u'childs': False, u'cincinnati': False, u'chain': False, u'whoever': False, u'separates': False, u'bandits': False, u'unraveled': False, u'chair': False, u'macht': False, u'ballet': False, u'malintentioned': False, u'grapples': False, u'graph': False, u'freelance': False, u'crates': False, u'crater': False, u'silencers': False, u'obssessed': False, u'macho': False, u'oversight': False, u'tenacious': False, u'1991': False, u'downloading': False, u'paychecks': False, u'jerk': False, u'tnt': False, u'jere': False, u'prancer': False, u'prances': False, u'choice': False, u'aissa': False, u'embark': False, u'gloomy': False, u'ghostbusters': False, u'stays': False, u'1995': False, u'exact': True, u'minute': False, u'cooks': False, u'scholl': False, u'1997': False, u'adorable': False, u'masturbates': False, u'minnie': False, u'skewed': False, u'mathew': False, u'skewer': False, u'matthau': False, u'xenophobe': False, u'trails': False, u'heavyweight': False, u'chopping': False, u'shirts': False, u'ogled': False, u'biopic': False, u'headset': False, u'lavishness': False, u'massironi': False, u'antwerp': False, u'celebrated': False, u'karras': False, u'tizard': False, u'celebrates': False, u'unintentionally': False, u'drafted': False, u'erb': False, u'oldies': False, u'climbs': False, u'blunted': False, u'topicality': False, u'gladys': False, u'address': False, u'dwindling': False, u'benson': False, u'mafioso': False, u'accomplishes': False, u'dusty': False, u'impacted': False, u'cusack': False, u'accomplished': False, u'sprouted': False, u'expressively': False, u'enrols': False, u'influx': False, u'kasinsky': False, u'architectural': False, u'houseman': False, u'substitution': False, u'betraying': False, u'jose': False, u'pees': False, u'fakery': False, u'hallie': False, u'darnell': False, u'undergone': False, u'working': False, u'oldham': False, u'quivering': False, u'opposed': False, u'unjust': False, u'familar': False, u'perishes': False, u'ooooooo': False, u'assimilation': False, u'consoles': False, u'riders': False, u'rebounding': False, u'pooper': False, u'originally': False, u'abortion': False, u'americanised': False, u'harmonious': False, u'remaning': False, u'following': False, u'zippers': False, u'admired': False, u'mirrors': False, u'stetson': False, u'parachute': False, u'locks': False, u'sextette': False, u'admires': False, u'admirer': False, u'succumbing': False, u'listens': False, u'gentler': False, u'septic': False, u'vainly': False, u'thanking': False, u'edouard': False, u'rewatched': False, u'mintues': False, u'mat': False, u'pesimism': False, u'casualness': False, u'mythos': False, u'convincingly': False, u'islamic': False, u'meddled': False, u'horks': False, u'brainless': False, u'egotistical': False, u'surfing': False, u'jonnie': False, u'conscious': False, u'regressive': False, u'nebbish': False, u'skirmish': False, u'wolves': False, u'pulled': False, u'manga': False, u'impactful': False, u'years': True, u'professors': False, u'structuring': False, u'episodes': False, u'marshmallows': False, u'professory': False, u'overlord': False, u'disconnect': False, u'slimeball': False, u'jia': False, u'milked': False, u'jim': False, u'troubles': False, u'pulitzer': False, u'rudnick': False, u'roadster': False, u'jip': False, u'suspension': False, u'troubled': False, u'modestly': False, u'sparing': False, u'recipients': False, u'civilian': False, u'courageously': False, u'indigenous': False, u'overpowering': False, u'drilling': False, u'workmanlike': False, u'henpecked': False, u'sorted': False, u'\\\\': False, u'josh': False, u'materialized': False, u'didn': True, u'didi': False, u'dispite': False, u'fisherman': False, u'battleships': False, u'instability': False, u'quarter': False, u'quartet': False, u'materializes': False, u'retrieve': False, u'policed': False, u'bursting': False, u'receipt': False, u'sponsor': False, u'entering': False, u'salads': False, u'disasters': False, u'bouyant': False, u'rioters': False, u'interned': False, u'yojimbo': False, u'1992': False, u'wiseguys': False, u'disaster_': False, u'seriously': False, u'trauma': False, u'firorina': False, u'internet': False, u'merpeople': False, u'ladder': False, u'igniting': False, u'rebuilding': False, u'complicates': False, u'disintegrated': False, u'hairdresser': False, u'sympathize': False, u'existentialist': False, u'complicated': False, u'mcferran': False, u'grandma': False, u'marla': False, u'eggar': False, u'bared': False, u'tomahawk': False, u'tasting': False, u'modest': False, u'marlo': False, u'initiate': False, u'aboard': False, u'socking': False, u'domed': False, u'neglect': False, u'emotion': False, u'gunshot': False, u'saving': False, u'symmetry': False, u'spoken': False, u'velda': False, u'savini': False, u'westlake': False, u'reprisal': False, u'one': True, u'respecting': False, u'ony': False, u'punishable': False, u'periodical': False, u'haviland': False, u'tamara': False, u'onw': False, u'plotless': False, u'exaggerations': False, u'stifler': False, u'stifles': False, u'jugs': False, u'tenko': False, u'davidovitch': False, u'stifled': False, u'backwoods': False, u'oversimplified': False, u'lingering': False, u'featherbrained': False, u'beesley': False, u'cherbourg': False, u'shawn': False, u'surges': False, u'obtained': False, u'snatch': False, u'devito': False, u'anthesis': False, u'absorbs': False, u'thai': False, u'padre': False, u'rza': False, u'hoyle': False, u'gisbourne': False, u'crossroads': False, u'admitedly': False, u'rehab': False, u'wandering': False, u'fruity': False, u'disasterous': False, u'dilemnas': False, u'bulow': False, u'illness': False, u'aaaaaaaahhhh': False, u'stylings': False, u'sumptuous': False, u'premier': False, u'turned': False, u'locations': False, u'jewels': False, u'balsan': False, u'odile': False, u'uninterrupted': False, u'infomercial': False, u'breakfast': False, u'emmylou': False, u'politicos': False, u'jacks': False, u'pimply': False, u'zoe': False, u'wcw': False, u'cigarettes': False, u'warriors': False, u'reasonable': False, u'zoo': False, u'goodman': False, u'portents': False, u'martineau': False, u'_titus_andronicus_': False, u'mayer': False, u'pimple': False, u'topping': False, u'opposite': False, u'discerning': False, u'spewing': False, u'buffet': False, u'printed': False, u'knowingly': False, u'buffed': False, u'captivatingly': False, u'wacked': False, u'touchy': False, u'phil': False, u'toucha': False, u'jitters': False, u'messier': False, u'wreaked': False, u'slaver': False, u'jittery': False, u'atlantic': False, u'delroy': False, u'wynn': False, u'fakeouts': False, u'imagines': False, u'friction': False, u'fecal': False, u'oderkerk': False, u'inconsistent': False, u'copyrighted': False, u'soviets': False, u'imagined': False, u'wynt': False, u'geography': False, u'zahn': False, u'reconciling': False, u'coaxing': False, u'goregeous': False, u'sierra': False, u'fades': False, u'guarded': False, u'rejoiced': False, u'suitcases': False, u'revolutionized': False, u'tilting': False, u'undetected': False, u'simplistic': False, u'awaiting': False, u'miming': False, u'wahlberg': False, u'pimp': False, u'trys': False, u'carrion': False, u'ambling': False, u'recoiling': False, u'choudhury': False, u'vision': False, u'morose': False, u'attenuated': False, u'underbids': False, u'audaciously': False, u'impressions': False, u'intoxicating': False, u'aboslutely': False, u'defensively': False, u'retells': False, u'masturbatory': False, u'alarming': False, u'feuds': False, u'sponsorship': False, u'moons': False, u'nicest': False, u'enjoys': False, u'playhouse': False, u'caan': False, u'tsui': False, u'lyricized': False, u'faded': False, u'braggarts': False, u'punts': False, u'awards': False, u'menacing': False, u'innuendos': False, u'smoggy': False, u'uncharacteristically': False, u'concentrated': False, u'busting': False, u'confection': False, u'majestically': False, u'rhodes': False, u'matheson': False, u'millionaire': False, u'flipped': False, u's': True, u'workplace': False, u'concentrates': False, u'flipper': False, u'doctoring': False, u'loveliest': False, u'beowolf': False, u'adroit': False, u'mugshots': False, u'imbues': False, u'comparitive': False, u'collides': False, u'west': False, u'deuteronomy': False, u'collided': False, u'brancia': False, u'motives': False, u'sked': False, u'nntphub': False, u'spyglass': False, u'wants': False, u'vomits': False, u'tomei': False, u'formed': False, u'photon': False, u'readings': False, u'photos': False, u'tightened': False, u'abject': False, u'former': False, u'sedition': False, u'sommers': False, u'chauvinistic': False, u'defeatist': False, u'straighten': False, u'squeezes': False, u'shockwave': False, u'diverse': False, u'newspaper': False, u'situation': False, u'slapping': False, u'landslide': False, u'penthouse': False, u'unlikeable': False, u'rapier': False, u'surveying': False, u'engaged': False, u'zucker': False, u'dubious': False, u'_still_': False, u'menancing': False, u'twotg': False, u'engages': False, u'multitudes': False, u'debilitating': False, u'ingrained': False, u'nuptials': False, u'fistfights': False, u'quiclky': False, u'otto': False, u'jessalyn': False, u'bogglingly': False, u'visually': False, u'wires': False, u'edged': False, u'assigns': False, u'hideaway': False, u'sickness': False, u'krippendorf': False, u'defy': False, u'brassed': False, u'deflate': False, u'tolan': False, u'edges': False, u'amuck': False, u'advertisement': False, u'ratttz': False, u'_seven_nights_': False, u'tracking': False, u'droppingly': False, u'charges': False, u'nothin': False, u'peculiarities': False, u'delectably': False, u'penetration': False, u'dimension': False, u'persistently': False, u'recycles': False, u'being': False, u'bueller': False, u'recycled': False, u'dick_': False, u'parlay': False, u'lonesome': False, u'procreating': False, u'rover': False, u'grounded': False, u'cloris': False, u'lifelong': False, u'gloating': False, u'overthrow': False, u'haystack': False, u'dicks': False, u'absense': False, u'phelps': False, u'sportsmanship': False, u'rejoin': False, u'sums': False, u'unveil': False, u'sumo': False, u'traffic': False, u'preference': False, u'politely': False, u'world': True, u'embrassment': False, u'postal': False, u'reap': False, u'likeablity': False, u'sensational': False, u'malfunctions': False, u'unrepentant': False, u'benefit': False, u'superiority': False, u'glamor': False, u'dirtier': False, u'petrice': False, u'confrontatory': False, u'satisfactory': False, u'superintendent': False, u'affay': False, u'dilbert': False, u'tvs': False, u'magma': False, u'demeaning': False, u'diving': False, u'stagecoach': False, u'divine': False, u'bongos': False, u'dancefloor': False, u'painstakingly': False, u'bottlecaps': False, u'cavity': False, u'seaman': False, u'squirt': False, u'francois': False, u'911': False, u'restoring': False, u'process': False, u'squabble': False, u'arrow': True, u'macgowan': False, u'retains': False, u'cliquey': False, u'tv2': False, u'leadership': False, u'piscapo': False, u'thailand': False, u'demarco': False, u'exasperating': False, u'loyalties': False, u'hopkins': False, u'majorino': False, u'ob': False, u'stanleyville': False, u'wrestled': False, u'frights': False, u'niall': False, u'chow': False, u'internalize': False, u'johnston': False, u'locklear': False, u'sensitively': False, u'rabbinical': False, u'perturbed': False, u'shapely': False, u'burial': False, u'antidote': False, u'kroon': False, u'ineffable': False, u'lively': False, u'bukater': False, u'pivot': False, u'conceptually': False, u'rossi': False, u'uhhhhhm': False, u'complexly': False, u'distractedness': False, u'vaporize': False, u'hunks': False, u'gleam': False, u'glean': False, u'lounging': False, u'redirection': False, u'mindless': False, u'missy': False, u'sealed': False, u'brazilian': False, u'bubble': False, u'witt': False, u'continents': False, u'wits': False, u'bohemians': False, u'lane': False, u'societal': False, u'foreheads': False, u'attainable': False, u'with': True, u'abused': False, u'pull': False, u'rush': False, u'thumps': False, u'dominican': False, u'rage': False, u'tripe': False, u'claustral': False, u'chomped': False, u'rags': False, u'dirty': False, u'abuser': False, u'abuses': False, u'russ': False, u'trips': False, u'touchstone': False, u'patois': False, u'falseness': False, u'wormwood': False, u'gratuitous': False, u'watches': False, u'watcher': False, u'associating': False, u'toontown': False, u'watched': False, u'jargon': False, u'tremble': False, u'dampens': False, u'cream': False, u'moniker': False, u'ideally': False, u'administered': False, u'yogi': False, u'sympathetically': False, u'unwelcomed': False, u'introspection': False, u'hofstra': False, u'unparalleled': False, u'friggin': False, u'puppy': False, u'addictions': False, u'artillary': False, u'waving': False, u'falstaff': False, u'midget': False, u'brotherhood': False, u'whippersnappers': False, u'torches': False, u'linebackers': False, u'fedoras': False, u'tricky': False, u'mourned': False, u'natalie': False, u'thora': False, u'tricks': False, u'maliciously': False, u'dyed': False, u'uploaded': False, u'finklestein': False, u'dyer': False, u'humoring': False, u'sci': False, u'anette': False, u'lopped': False, u'caused': False, u'beware': False, u'slimming': False, u'zappa': False, u'upholds': False, u'causes': False, u'riots': False, u'nora': False, u'conciousness': False, u'carters': False, u'norm': False, u'gazarra': False, u'clubbed': False, u'powaqqatsi': False, u'floated': False, u'clubber': False, u'24th': False, u'suspensefully': False, u'sant': False, u'rootless': False, u'sans': False, u'boozed': False, u'shenanigans': False, u'sang': False, u'sand': False, u'sane': False, u'unwraps': False, u'small': False, u'sank': False, u'vanquish': False, u'courtesans': False, u'abbreviated': False, u'quicker': False, u'traditions': False, u'tardis': False, u'healed': False, u'past': False, u'displays': False, u'pass': False, u'healer': False, u'investment': False, u'amarcord': False, u'clock': False, u'skywalker': False, u'leit': False, u'colonists': False, u'leia': False, u'psychoanalysts': False, u'dwells': False, u'hasn': False, u'full': False, u'hash': False, u'diapers': False, u'portrays': False, u'civilians': False, u'november': False, u'hass': False, u'melancholic': False, u'contrastingly': False, u'ivey': False, u'experience': False, u'anthropologists': False, u'prior': False, u'beaman': False, u'periodic': False, u'holdover': False, u'cessation': False, u'divison': False, u'skepticism': False, u'hime': False, u'amadeus': False, u'uniquely': False, u'interactivity': False, u'norville': False, u'followed': False, u'retroactive': False, u'mediator': False, u'scharzenegger': False, u'traumatized': False, u'follower': False, u'analyzing': False, u'traumatizes': False, u'cynics': False, u'enlightened': False, u'automats': False, u'volcanos': False, u'silva': False, u'attendance': False, u'enliven': False, u'canoe': False, u'briesewitz': False, u'lollipop': False, u'mori': False, u'unrecognizable': False, u'certified': False, u'restraints': False, u'firth': False, u'mora': False, u'glowers': False, u'more': True, u'israel': False, u'barbarino': False, u'door': False, u'doos': False, u'initiated': False, u'chucky': False, u'company': False, u'corrected': False, u'tested': False, u'lameness': False, u'fumble': False, u'doom': False, u'negativity': False, u'leary': False, u'kaminski': False, u'fornicators': False, u'maniac': False, u'patriarch': False, u'kaminsky': False, u'learn': False, u'knocked': False, u'grope': False, u'scramble': False, u'barclay': False, u'allegra': False, u'bogs': False, u'memoirs': False, u'meaner': False, u'bogg': False, u'aatish': False, u'prostration': False, u'sikh': False, u'huge': False, u'respective': False, u'hickey': False, u'edgecomb': False, u'demolition': False, u'speedboat': False, u'hugo': False, u'hugh': False, u'dismissed': False, u'hugs': False, u'dismisses': False, u'isuro': False, u'sprinkle': False, u'lanky': False, u'intended': False, u'mendes': False, u'thickened': False, u'disgraced': False, u'greenwald': False, u'hackwork': False, u'maltese': False, u'dryland': False, u'malevolent': False, u'jiang': False, u'resemble': False, u'sublte': False, u'twisting': False, u'tiegs': False, u'dolph': False, u'overcooked': False, u'replied': False, u'weirdoes': False, u'depraved': False, u'peppy': False, u'installed': False, u'resorts': False, u'paper': False, u'scott': False, u'signs': False, u'smiling': False, u'signy': False, u'roots': False, u'saucy': False, u'mistreated': False, u'tantalizingly': False, u'ethnocentric': False, u'sublimated': False, u'hounds': False, u'isaak': False, u'blunderheaded': False, u'dolly': False, u'bummer': False, u'isaac': False, u'sauce': False, u'reintroduced': False, u'colleague': False, u'cartman': False, u'frizzi': False, u'abandons': False, u'universality': False, u'gadget': False, u'frizzy': False, u'balaban': False, u'weeds': False, u'idols': False, u'everytime': False, u'denny': False, u'courses': False, u'unbrewed': False, u'hatchette': False, u'repayment': False, u'shocking': False, u'reactions': False, u'brunette': False, u'another': False, u'numeric': False, u'scalvaging': False, u'chrissy': False, u'operation': False, u'centuries': False, u'inquired': False, u'lipstick': False, u'ernie': False, u'kensington': False, u'buzzsaw': False, u'research': False, u'inquires': False, u'illustrate': False, u'occurs': False, u'abnormally': False, u'poignantly': False, u'definition': False, u'pairs': False, u'2056': False, u'theroux': False, u'unjustifyably': False, u'testament': False, u'existential': False, u'porpoise': False, u'petra': False, u'horndog': False, u'seduction': False, u'trekkie': False, u'terrifyingly': False, u'brutally': False, u'preservation': False, u'burke': False, u'arlington': False, u'nomi': False, u'moderately': False, u'heartedness': False, u'bigscreen': False, u'excitable': False, u'bedridden': False, u'saint': False, u'kindergartner': False, u'essays': False, u'peaceably': False, u'nursery': False, u'justly': False, u'dethroned': False, u'interviewed': False, u'typhoon': False, u'cheekbones': False, u'chapelle': False, u'theater': False, u'stifle': False, u'oilrig': False, u'dethrones': False, u'pyroclastic': False, u'funicello': False, u'stormare': False, u'condolences': False, u'bruckheimer': False, u'getaway': False, u'dogs': False, u'dismantling': False, u'beneficial': False, u'prescott': False, u'labyrinthian': False, u'navigators': False, u'kret': False, u'mensch': False, u'organisations': False, u'swanky': False, u'waft': False, u'berle': False, u'guarding': False, u'graffiti': False, u'blond': False, u'cleon': False, u'cleverness': False, u'sell': False, u'nosebleeding': False, u'antagonizes': False, u'tarnish': False, u'self': False, u'sela': False, u'client': False, u'also': True, u'recognizing': False, u'sebastiano': False, u'conscription': False, u'sharpe': False, u'bastad': False, u'pringles': False, u'singles': False, u'raucous': False, u'virus': False, u'channeling': False, u'immediacy': False, u'singled': False, u'understands': False, u'omaha': False, u'seize': False, u'sometimes': False, u'flits': False, u'barred': False, u'cultivating': False, u'barren': False, u'barrel': False, u'shread': False, u'amusements': False, u'dragonflies': False, u'ambiguities': False, u'ugh': False, u'ugc': False, u'blended': False, u'accommodations': False, u'colorized': False, u'prodigious': False, u'naomi': False, u'overwhelmed': False, u'caruso': False, u'wraps': False, u'kinkiness': False, u'neophytes': False, u'turmoil': False, u'gooey': False, u'cassette': False, u'snobbish': False, u'crashlands': False, u'indifference': False, u'lombard': False, u'haskin': False, u'secular': False, u'ceasing': False, u'sunny': False, u'asssss': False, u'informants': False, u'yeager': False, u'remedy': False, u'compass': False, u'damnit': False, u'distraction': False, u'devoured': False, u'sects': False, u'pleasures': False, u'tanked': False, u'sojourn': False, u'tanker': False, u'pleasured': False, u'rumored': False, u'insane': False, u'delicately': False, u'bozo': False, u'activists': False, u'collectively': False, u'overboard': False, u'allie': False, u'glistening': False, u'richelieu': False, u'commensurately': False, u'ahmet': False, u'storyboarded': False, u'wopr': False, u'15th': False, u'goggins': False, u'untouched': False, u'coffee': False, u'canran': False, u'lass': False, u'last': False, u'legitimately': False, u'opal': False, u'swigert': False, u'connection': False, u'amoeba': False, u'opar': False, u'retarded': False, u'lash': False, u'onofrio': False, u'bell': False, u'2293': False, u'acted': False, u'adaptation': False, u'seldes': False, u'belt': False, u'unthrilling': False, u'warfield': False, u'unarguably': False, u'satire': False, u'suburbs': False, u'proprietor': False, u'initiation': False, u'portait': False, u'faulkner': False, u'patrolled': False, u'combatants': False, u'infect': False, u'amphibians': False, u'adaptable': False, u'awake': False, u'mournful': False, u'magwitch': False, u'exponential': False, u'caged': False, u'expanded': False, u'budget': False, u'admire': False, u'reopens': False, u'cagey': False, u'pressed': False, u'frighteners': False, u'bogan': False, u'cages': False, u'beatng': False, u'voe': False, u'agitation': False, u'mystic': False, u'von': False, u'binding': False, u'faceted': False, u'vow': False, u'underlining': False, u'cuisine': False, u'raiders': False, u'jerking': False, u'perpetrator': False, u'pridefully': False, u'matchmakers': False, u'cayman': False, u'ugliness': False, u'windmill': False, u'praising': False, u'flooded': False, u'everclear': False, u'reiser': False, u'fleischer': False, u'wunderkind': False, u'vargas': False, u'infamous': False, u'symbolise': False, u'doreen': False, u'prehensile': False, u'coachmen': False, u'dared': False, u'portillo': False, u'scoffs': False, u'thats': False, u'soaked': False, u'pepto': False, u'salva': False, u'cheddar': False, u'crackled': False, u'thaddeus': False, u'hercules': False, u'crackles': False, u'wage': False, u'hemingwayesque': False, u'cuffs': False, u'melinda': False, u'rangers': False, u'studious': False, u'parents': False, u'depravity': False, u'boardroom': False, u'eery': False, u'cormack': False, u'emergency': False, u'impaling': False, u'couple': False, u'bureaucrat': False, u'emanating': False, u'wives': False, u'ofcs': False, u'abound': False, u'emergence': False, u'thurman': False, u'marquee': False, u'spine': False, u'chorus': False, u'individuals': False, u'crookier': False, u'bogie': False, u'mediocrity': False, u'bamboo': False, u'turvy': False, u'alexandre': False, u'spins': False, u'crescendo': False, u'methods': False, u'goddamn': False, u'unsubstantial': False, u'bounce': False, u'ahern': False, u'bouncy': False, u'greener': False, u'underbelly': False, u'obliges': False, u'measurements': False, u'novelty': False, u'pell': False, u'behave': False, u'whodunit': False, u'metamorphoses': False, u'seclusion': False, u'inserting': False, u'dialogueless': False, u'hammond': False, u'jovovich': False, u'wayward': False, u'obscures': False, u'respite': False, u'grotesqe': False, u'janusz': False, u'obscured': False, u'cranked': False, u'deserved': False, u'simplify': False, u'goody': False, u'scorces': False, u'wrinkles': False, u'melbourne': False, u'deserves': False, u'scraggly': False, u'maude': False, u'wrinkled': False, u'gallagher': False, u'canning': False, u'laughton': False, u'tornatore': False, u'_dead_': False, u'terrorists': False, u'into': True, u'unredeemable': False, u'catchiness': False, u'middleton': False, u'controversies': False, u'remembrance': False, u'chirping': False, u'katie': False, u'realisation': False, u'span': False, u'harnessed': False, u'spam': False, u'tingles': False, u'sock': False, u'gases': False, u'bios': False, u'limburgher': False, u'grave': False, u'mishandle': False, u'spar': False, u'purred': False, u'spat': False, u'considerably': False, u'atlantis': False, u'invite': False, u'hawaiian': False, u'murphy': False, u'palentologist': False, u'_dragon_': False, u'deductions': False, u'lydia': False, u'carping': False, u'fanatasies': False, u'considerable': False, u'intestines': False, u'jacki': False, u'remastered': False, u'charmed': False, u'erich': False, u'pissant': False, u'testaments': False, u'eddie': False, u'erica': False, u'paired': False, u'tamahori': False, u'kihlstedt': False, u'awestruck': False, u'chad': False, u'pseudonymous': False, u'influence': False, u'haunt': False, u'portentuous': False, u'globally': False, u'thomsen': False, u'chap': False, u'revelatory': False, u'palisades': False, u'chat': False, u'apropos': False, u'chaz': False, u'frontgate': False, u'immeadiately': False, u'neilsen': False, u'intrepid': False, u'puzzling': False, u'copulate': False, u'thanks': False, u'excuses': False, u'conceptions': False, u'ellen': False, u'singed': False, u'heebie': False, u'aunt': False, u'rabal': False, u'interogation': False, u'oblige': False, u'gardenia': False, u'teck': False, u'strums': False, u'aussies': False, u'prepared': False, u'bianca': False, u'mckidd': False, u'flyboy': False, u'suppression': False, u'euphegenia': False, u'lang': False, u'guitry': False, u'land': False, u'ryan_': False, u'lana': False, u'advertisment': False, u'purged': False, u'reserve': False, u'modernizing': False, u'zzzzzzz': False, u'splashing': False, u'spielbergization': False, u'unbuttoning': False, u'broader': False, u'amiss': False, u'flashback': False, u'humpback': False, u'coffey': False, u'detectives': False, u'amalgamation': False, u'turkish': False, u'ditzism': False, u'horsing': False, u'dickinson': False, u'carelessly': False, u'resources': False, u'nervousness': False, u'lindner': False, u'boatload': False, u'undeterred': False, u'millieu': False, u'alienbusting': False, u'hockley': False, u'huddled': False, u'prakazrel': False, u'traumatised': False, u'scatology': False, u'koppelman': False, u'petitions': False, u'decorating': False, u'herzfeld': False, u'detested': False, u'yakov': False, u'lombardo': False, u'rifling': False, u'integrating': False, u'fewer': False, u'damning': False, u'yevgeny': False, u'disheveled': False, u'insubordinate': False, u'leonardi': False, u'leonardo': False, u'villiany': False, u'maclachlan': False, u'overblown': False, u'dysfuntion': False, u'cannibals': False, u'mishap': False, u'crook': False, u'video': True, u'dynamics': False, u'elisa': False, u'victor': False, u'improvisationaly': False, u'narrations': False, u'sweats': False, u'waning': False, u'harvests': False, u'sweaty': False, u'henceforth': False, u'royalist': False, u'turnaround': False, u'slickster': False, u'flowing': False, u'charade': False, u'harassing': False, u'guamo': False, u'forwarned': False, u'apace': False, u'squirming': False, u'fifteen': False, u'implicit': False, u'kriss': False, u'bakersfield': False, u'33': False, u'unwittingly': False, u'scatter': False, u'condescending': False, u'panned': False, u'survey': False, u'climb': False, u'makes': True, u'maker': False, u'looted': False, u'bumming': False, u'panicked': False, u'blizzard': False, u'formulates': False, u'dumbest': False, u'chilly': False, u'desiring': False, u'confidence': False, u'excising': False, u'pfarrer': False, u'gregor': False, u'zsigmond': False, u'next': False, u'eleven': False, u'assuring': False, u'mccleod': False, u'chu': False, u'tahoe': False, u'binges': False, u'phallus': False, u'yugoslavian': False, u'pencil': False, u'babe': False, u'spearing': False, u'tons': True, u'duper': False, u'babs': False, u'boondocks': False, u'prizes': False, u'losin': False, u'baby': False, u'antichrist': False, u'_escape': False, u'documentarian': False, u'customer': False, u'f': False, u'clients': False, u'unknowns': False, u'retell': False, u'harve': False, u'initation': False, u'rehabilitation': False, u'wedge': False, u'loca': False, u'painkiller': False, u'calculation': False, u'lock': False, u'coolness': False, u'loco': False, u'promotional': False, u'aughra': False, u'nears': False, u'bolstered': False, u'taj': False, u'cecilia': False, u'educational': False, u'afi': False, u'raeeyain': False, u'awkwardness': False, u'paled': False, u'schandling': False, u'tightrope': False, u'procured': False, u'neary': False, u'bilingual': False, u'hormones': False, u'burley': False, u'engagingly': False, u'intelligent': False, u'pales': False, u'incongruent': False, u'highs': False, u'huffs': False, u'retrograding': False, u'upstate': False, u'procures': False, u'infirm': False, u'realized': False, u'jolting': False, u'solon': False, u'clarkson': False, u'shout': False, u'robot': False, u'realizes': False, u'scrubs': False, u'sciorra': False, u'typicalness': False, u'marshalls': False, u'bartenders': False, u'houston': False, u'boxing': False, u'thigh': False, u'mute': False, u'muth': False, u'despite': True, u'frieberg': False, u'spatula': False, u'directs': False, u'bartusiak': False, u'hotcakes': False, u'perfect': False, u'anonymously': False, u'byline': False, u'rizzo': False, u'jetsons': False, u'meantime': True, u'thieves': False, u'derivative': False, u'90210': False, u'sabotaging': False, u'prosper': False, u'vocalized': False, u'impervious': False, u'overal': False, u'isacsson': False, u'guaspari': False, u'reinvents': False, u'snake': False, u'squabbling': False, u'realize': False, u'reconstruction': False, u'comedy': False, u'damian': False, u'scenic': False, u'zeist': False, u'denzel': False, u'shortage': False, u'weismuller': False, u'emo': False, u'glasses': False, u'goldsman': False, u'suitors': False, u'bump': False, u'poppins': False, u'bums': False, u'deficiency': False, u'leplastrier': False, u'books': False, u'resuscitate': False, u'gungan': False, u'bigfoot': False, u'witness': False, u'unoriginal': False, u'matrix': False, u\"'\": True, u'harrowingly': False, u'narratively': False, u'frowns': False, u'unprepared': False, u'hypnotist': False, u'red': False, u'unwieldy': False, u'benben': False, u'inferiority': False, u'greedy': False, u'gawain': False, u'disintegrating': False, u'initialize': False, u'pothead': False, u'mainland': False, u'fueled': False, u'blandy': False, u'gallons': False, u'could': False, u'genieveve': False, u'length': False, u'chills': False, u'babyzilla': False, u'fleshed': False, u'scene': False, u'reaches': False, u'soothing': False, u'affliction': False, u'leick': False, u'morice': False, u'scent': False, u'fleshes': False, u'braces': False, u'erstwhile': False, u'leder': False, u'festival': False, u'lumet': False, u'rediscovers': False, u'fanaro': False, u'stabbin': False, u'sergeant': False, u'henning': False, u'pervasive': False, u'enforcement': False, u'zookeeper': False, u'stomach': False, u'quarry': False, u'greenbaum': False, u'pulman': False, u'beastuality': False, u'incongruities': False, u'fatboy': False, u'egregious': False, u'roulette': False, u'commandant': False, u'gentile': False, u'orchestrated': False, u'daydreams': False, u'mackey': False, u'faulted': False, u'false': False, u'shrinks': False, u'chivalrous': False, u'tonight': False, u'ponders': False, u'richman': False, u'sufis': False, u'cecil': False, u'hessian': False, u'depict': False, u'venturing': False, u'dishes': False, u'fireballs': False, u'mia': False, u'dodie': False, u'mib': False, u'precipice': False, u'dished': False, u'bakshi': False, u'sandworms': False, u'worldwide': False, u'jimmies': False, u'closeups': False, u'manor': False, u'fujioka': False, u'petals': False, u'cipher': False, u'draws': False, u'unsexy': False, u'hoodwink': False, u'salutory': False, u'unsparing': False, u'doogie': False, u'auberjonois': False, u'placement': False, u'introversion': False, u'wuthering': False, u'bred': False, u'thanksgiving': False, u'lots': False, u'perceiving': False, u'undersea': False, u'brew': False, u'bret': False, u'rainbows': False, u'woolly': False, u'greenhouse': False, u'nominally': False, u'xvi': False, u'taps': False, u'jax': False, u'jay': False, u'jaw': False, u'consciouness': False, u'jar': False, u'risqueness': False, u'gascogne': False, u'jan': False, u'entities': False, u'jam': False, u'tape': False, u'jah': False, u'jai': False, u'riding': False, u'jab': False, u'abbe': False, u'insight': True, u'cooperation': False, u'abba': False, u'antagonism': False, u'prohibition': False, u'molasses': False, u'drawn': False, u'tossed': False, u'wring': False, u'styrofoam': False, u'abby': False, u'gertz': False, u'rapper': False, u'comprising': False, u'taxes': False, u'shields': False, u'coaxed': False, u'ocmic': False, u'stuff': False, u'ohio': False, u'rapped': False, u'raceway': False, u'exude': False, u'guessing': False, u'allusion': False, u'qinqin': False, u'frame': False, u'hijinx': False, u'arsed': False, u'kombat_': False, u'alessandro': False, u'trods': False, u'siegfried': False, u'deconstructs': False, u'dungeon': False, u'destiny': False, u'insulting': False, u'nuclear': False, u'comprehendably': False, u'melrose': False, u'comprehendable': False, u'repetitively': False, u'nesmith': False, u'preminger': False, u'keynote': False, u'quirkyness': False, u'ifans': False, u'refuting': False, u'lawsuit': False, u'staring': False, u'marty': False, u'hammy': False, u'swann': False, u'marts': False, u'flanery': False, u'doorway': False, u'unearthing': False, u'vadar': False, u'conclude': False, u'roughed': False, u'stylistically': False, u'confronts': False, u'novalee': False, u'mailman': False, u'midland': False, u'catholicism': False, u'kahl': False, u'kahn': False, u'eviscerated': False, u'yoram': False, u'feather': False, u'>': False, u'butchers': False, u'marcellus': False, u'altruist': False, u'sheepish': False, u'commuter': False, u'commutes': False, u'swarmed': False, u'coherence': False, u'hateful': False, u'swindling': False, u'banish': False, u'miscommunicated': False, u'lecherous': False, u'reminiscence': False, u'gamesmanship': False, u'eaton': False, u'farsical': False, u'hahaha': False, u'fielding': False, u'miyake': False, u'stuffing': False, u'lawerence': False, u'lascivious': False, u'incense': False, u'ransom': False, u'tattoo': False, u'ostentatious': False, u'moves': False, u'pauly': False, u'subtitling': False, u'paull': False, u'painstaking': False, u'gibbs': False, u'pickin': False, u'chronicling': False, u'paula': False, u'unimaginable': False, u'complemented': False, u'unsympathetic': False, u'censoring': False, u'fraidy': False, u'berardinelli': False, u'identity': False, u'ofa': False, u'off': True, u'shotgun': False, u'dissing': False, u'patterns': False, u'oft': False, u'audio': False, u'tactfully': False, u'quentin': False, u'braniff': False, u'newest': False, u'obscenity': False, u'dissatisfying': False, u'souped': False, u'coalwood': False, u'clocks': False, u'diedre': False, u'unmitigatedly': False, u'web': False, u'tong': False, u'wee': False, u'hauntingly': False, u'wei': False, u'wen': False, u'toyed': False, u'undulating': False, u'wes': True, u'toni': False, u'wet': False, u'practise': False, u'villagers': False, u'tics': False, u'pieh': False, u'pied': False, u'crud': False, u'stooped': False, u'falters': False, u'mutations': False, u'crux': False, u'cruz': False, u'zimbabwe': False, u'hallucinates': False, u'atrophy': False, u'piet': False, u'tick': False, u'pier': False, u'pies': False, u'debatable': False, u'emma': False, u'bulge': False, u'mistrustful': False, u'flickering': False, u'become': False, u'emmy': False, u'assasination': False, u'palladino': False, u'nutsy': False, u'knifepoint': False, u'brainerd': False, u'underwent': False, u'basque': False, u'_pick_chucky_up_': False, u'immortal': False, u'petey': False, u'gymnastics': False, u'choosing': False, u'flush': False, u'hissing': False, u'humming': False, u'recognition': False, u'delaurentiis': False, u'hipsters': False, u'mementos': False, u'buehler': False, u'passion': False, u'copulation': False, u'biology': False, u'uhhhm': False, u'brokering': False, u'pressure': False, u'infiltrating': False, u'imaginary': False, u'coldly': False, u'homemaker': False, u'iwai': False, u'lifestyle': False, u'langer': False, u'burroughs': False, u'outshines': False, u'blackness': False, u'sadoski': False, u'documentary': False, u'swimming': False, u'promiss': False, u'letters': False, u'miscegenation': False, u'rochon': False, u'hang': False, u'compadre': False, u'mojorino': False, u'privates': False, u'terminated': False, u'letter_': False, u'brides': False, u'pairing': False, u'peters': False, u'heresy': False, u'indoctrinated': False, u'rhythmic': False, u'yarns': False, u'moonstruck': False, u'progenitor': False, u'contradictory': False, u'jerkish': False, u'bagger': False, u'counterparts': False, u'zaniness': False, u'unformal': False, u'places': False, u'bloodline': False, u'congresswoman': False, u'excitement': False, u'placed': False, u'mouseketeer': False, u'tosses': False, u'problem': True, u'unsupportive': False, u'nurses': False, u'_lot_': False, u'lobotomise': False, u'walters': False, u'effected': False, u'compared': False, u'nonetheless': False, u'deadly': False, u'purproses': False, u'lately': False, u'kerrigans': False, u'compares': False, u'details': False, u'boon': False, u'behold': False, u'vulgarize': False, u'illusion': False, u'ponytail': False, u'rebelled': False, u'repeat': False, u'zhou': False, u'treason': False, u'allotting': False, u'impregnating': False, u'tinier': False, u'trunchbull': False, u'laude': False, u'exposure': False, u'searches': False, u'ustinov': False, u'disatisfaction': False, u'mishears': False, u'torrid': False, u'compete': False, u'lestat': False, u'villainous': False, u'searched': False, u'gardens': False, u'homerian': False}\n"
     ]
    }
   ],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "featuresets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. [Naive Bayes Classifier with NLTK](https://pythonprogramming.net/naive-bayes-classifier-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15355406/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier accuracy percent:', 68.0)\n"
     ]
    }
   ],
   "source": [
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:1900]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n               insulting = True              neg : pos    =     10.7 : 1.0\n                  doubts = True              pos : neg    =      9.5 : 1.0\n                    sans = True              neg : pos    =      8.4 : 1.0\n              mediocrity = True              neg : pos    =      7.8 : 1.0\n                 wasting = True              neg : pos    =      7.8 : 1.0\n            refreshingly = True              pos : neg    =      7.6 : 1.0\n               dismissed = True              pos : neg    =      6.9 : 1.0\n             bruckheimer = True              neg : pos    =      6.4 : 1.0\n                   wires = True              neg : pos    =      6.4 : 1.0\n                  fabric = True              pos : neg    =      6.3 : 1.0\n             overwhelmed = True              pos : neg    =      6.3 : 1.0\n                     ugh = True              neg : pos    =      5.9 : 1.0\n               uplifting = True              pos : neg    =      5.8 : 1.0\n                  bounce = True              neg : pos    =      5.7 : 1.0\n                    lang = True              pos : neg    =      5.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. [Saving Classifiers with NLTK](https://pythonprogramming.net/pickle-classifier-save-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15355460/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n               insulting = True              neg : pos    =     10.7 : 1.0\n                  doubts = True              pos : neg    =      9.5 : 1.0\n                    sans = True              neg : pos    =      8.4 : 1.0\n              mediocrity = True              neg : pos    =      7.8 : 1.0\n                 wasting = True              neg : pos    =      7.8 : 1.0\n            refreshingly = True              pos : neg    =      7.6 : 1.0\n               dismissed = True              pos : neg    =      6.9 : 1.0\n             bruckheimer = True              neg : pos    =      6.4 : 1.0\n                   wires = True              neg : pos    =      6.4 : 1.0\n                  fabric = True              pos : neg    =      6.3 : 1.0\n             overwhelmed = True              pos : neg    =      6.3 : 1.0\n                     ugh = True              neg : pos    =      5.9 : 1.0\n               uplifting = True              pos : neg    =      5.8 : 1.0\n                  bounce = True              neg : pos    =      5.7 : 1.0\n                    lang = True              pos : neg    =      5.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "classifier_f = open(\"naivebayes.pickle\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. [Scikit-Learn Sklearn with NLTK](https://pythonprogramming.net/sklearn-scikit-learn-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15355745/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Original Naive Bayes Algo accuracy percent:', 68.0)\nMost Informative Features\n               insulting = True              neg : pos    =     10.7 : 1.0\n                  doubts = True              pos : neg    =      9.5 : 1.0\n                    sans = True              neg : pos    =      8.4 : 1.0\n              mediocrity = True              neg : pos    =      7.8 : 1.0\n                 wasting = True              neg : pos    =      7.8 : 1.0\n            refreshingly = True              pos : neg    =      7.6 : 1.0\n               dismissed = True              pos : neg    =      6.9 : 1.0\n             bruckheimer = True              neg : pos    =      6.4 : 1.0\n                   wires = True              neg : pos    =      6.4 : 1.0\n                  fabric = True              pos : neg    =      6.3 : 1.0\n             overwhelmed = True              pos : neg    =      6.3 : 1.0\n                     ugh = True              neg : pos    =      5.9 : 1.0\n               uplifting = True              pos : neg    =      5.8 : 1.0\n                  bounce = True              neg : pos    =      5.7 : 1.0\n                    lang = True              pos : neg    =      5.6 : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MNB_classifier accuracy percent:', 68.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BernoulliNB_classifier accuracy percent:', 69.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LogisticRegression_classifier accuracy percent:', 66.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGDClassifier_classifier accuracy percent:', 63.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVC_classifier accuracy percent:', 44.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearSVC_classifier accuracy percent:', 55.00000000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NuSVC_classifier accuracy percent:', 61.0)\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. [Combining Algorithms with NLTK](https://pythonprogramming.net/combine-classifier-algorithms-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15355927/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Original Naive Bayes Algo accuracy percent:', 89.0)\nMost Informative Features\n               insulting = True              neg : pos    =     10.7 : 1.0\n                  doubts = True              pos : neg    =      9.5 : 1.0\n                    sans = True              neg : pos    =      8.4 : 1.0\n              mediocrity = True              neg : pos    =      7.8 : 1.0\n                 wasting = True              neg : pos    =      7.8 : 1.0\n            refreshingly = True              pos : neg    =      7.6 : 1.0\n               dismissed = True              pos : neg    =      6.9 : 1.0\n             bruckheimer = True              neg : pos    =      6.4 : 1.0\n                   wires = True              neg : pos    =      6.4 : 1.0\n                  fabric = True              pos : neg    =      6.3 : 1.0\n             overwhelmed = True              pos : neg    =      6.3 : 1.0\n                     ugh = True              neg : pos    =      5.9 : 1.0\n               uplifting = True              pos : neg    =      5.8 : 1.0\n                  bounce = True              neg : pos    =      5.7 : 1.0\n                    lang = True              pos : neg    =      5.6 : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MNB_classifier accuracy percent:', 74.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BernoulliNB_classifier accuracy percent:', 74.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LogisticRegression_classifier accuracy percent:', 70.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGDClassifier_classifier accuracy percent:', 64.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearSVC_classifier accuracy percent:', 70.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NuSVC_classifier accuracy percent:', 71.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('voted_classifier accuracy percent:', 75.0)\n('Classification:', u'pos', 'Confidence %:', 0)\n('Classification:', u'pos', 'Confidence %:', 0)\n('Classification:', u'neg', 'Confidence %:', 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classification:', u'pos', 'Confidence %:', 100)\n('Classification:', u'neg', 'Confidence %:', 0)\n('Classification:', u'neg', 'Confidence %:', 0)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "        \n",
    "training_set = featuresets[:1900]\n",
    "testing_set =  featuresets[1900:]\n",
    "\n",
    "#classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "classifier_f = open(\"naivebayes.pickle\",\"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(classifier,\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  SGDClassifier_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n",
    "\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[0][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[0][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[1][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[1][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[2][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[2][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[3][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[3][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[4][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[4][0])*100)\n",
    "print(\"Classification:\", voted_classifier.classify(testing_set[5][0]), \"Confidence %:\",voted_classifier.confidence(testing_set[5][0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. [Investigating bias with NLTK](https://pythonprogramming.net/investigating-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15356098/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. [Improving Training Data for sentiment analysis with NLTK](https://pythonprogramming.net/new-data-set-training-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15356221/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf8' codec can't decode byte 0xf3 in position 4645: invalid continuation byte",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3add54aa8726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mshort_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nlp/hello_nltk/short_reviews/positive.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mshort_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nlp/hello_nltk/short_reviews/negative.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda2\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size, chars, firstline)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbytebuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnewdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                 \u001b[0mnewchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecodedbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfirstline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0xf3 in position 4645: invalid continuation byte"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "        \n",
    "short_pos = open(\"nlp/hello_nltk/short_reviews/positive.txt\",\"r\").read()\n",
    "short_neg = open(\"nlp/hello_nltk/short_reviews/negative.txt\",\"r\").read()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for r in short_pos.split('\\n'):\n",
    "    documents.append( (r, \"pos\") )\n",
    "\n",
    "for r in short_neg.split('\\n'):\n",
    "    documents.append( (r, \"neg\") )\n",
    "\n",
    "\n",
    "all_words = []\n",
    "\n",
    "short_pos_words = word_tokenize(short_pos)\n",
    "short_neg_words = word_tokenize(short_neg)\n",
    "\n",
    "for w in short_pos_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "for w in short_neg_words:\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "# positive data example:      \n",
    "training_set = featuresets[:10000]\n",
    "testing_set =  featuresets[10000:]\n",
    "\n",
    "##\n",
    "### negative data example:      \n",
    "##training_set = featuresets[100:]\n",
    "##testing_set =  featuresets[:100]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "##SVC_classifier = SklearnClassifier(SVC())\n",
    "##SVC_classifier.train(training_set)\n",
    "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. [Creating a module for Sentiment Analysis with NLTK](https://pythonprogramming.net/sentiment-analysis-module-nltk-tutorial/) | [video](https://www.bilibili.com/video/av15356391/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "    \n",
    "short_pos = open(\"short_reviews/positive.txt\",\"r\").read()\n",
    "short_neg = open(\"short_reviews/negative.txt\",\"r\").read()\n",
    "\n",
    "# move this up here\n",
    "all_words = []\n",
    "documents = []\n",
    "\n",
    "\n",
    "#  j is adject, r is adverb, and v is verb\n",
    "#allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "for p in short_pos.split('\\n'):\n",
    "    documents.append( (p, \"pos\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "    \n",
    "for p in short_neg.split('\\n'):\n",
    "    documents.append( (p, \"neg\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "\n",
    "\n",
    "save_documents = open(\"pickled_algos/documents.pickle\",\"wb\")\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "\n",
    "save_word_features = open(\"pickled_algos/word_features5k.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "###############\n",
    "save_classifier = open(\"pickled_algos/originalnaivebayes5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LogisticRegression_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LinearSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "##NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "##NuSVC_classifier.train(training_set)\n",
    "##print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDC_classifier.train(training_set)\n",
    "print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/SGDC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(SGDC_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'pickled_algos/documents.pickle'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2e7e2625bac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdocuments_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pickled_algos/documents.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocuments_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mdocuments_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'pickled_algos/documents.pickle'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "\n",
    "documents_f = open(\"pickled_algos/documents.pickle\", \"rb\")\n",
    "documents = pickle.load(documents_f)\n",
    "documents_f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word_features5k_f = open(\"pickled_algos/word_features5k.pickle\", \"rb\")\n",
    "word_features = pickle.load(word_features5k_f)\n",
    "word_features5k_f.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "featuresets_f = open(\"pickled_algos/featuresets.pickle\", \"rb\")\n",
    "featuresets = pickle.load(featuresets_f)\n",
    "featuresets_f.close()\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos/originalnaivebayes5k.pickle\", \"rb\")\n",
    "classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos/MNB_classifier5k.pickle\", \"rb\")\n",
    "MNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\", \"rb\")\n",
    "BernoulliNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos/LogisticRegression_classifier5k.pickle\", \"rb\")\n",
    "LogisticRegression_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos/LinearSVC_classifier5k.pickle\", \"rb\")\n",
    "LinearSVC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"pickled_algos/SGDC_classifier5k.pickle\", \"rb\")\n",
    "SGDC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiment(\"This movie was awesome! The acting was great, plot was wonderful, and there were pythons...so yea!\"))\n",
    "print(sentiment(\"This movie was utter junk. There were absolutely 0 pythons. I don't see what the point was at all. Horrible movie, 0/10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 20. []() | []()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 21. []() | []()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}